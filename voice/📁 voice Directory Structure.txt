ğŸ“ voice/ Directory Structure
plaintext
Copy
Edit
voice/
â”œâ”€â”€ database.py
â”œâ”€â”€ identity_helpers.py
â”œâ”€â”€ manager.py
â”œâ”€â”€ manager_context.py
â”œâ”€â”€ manager_core.py
â”œâ”€â”€ manager_names.py
â”œâ”€â”€ recognition.py
â”œâ”€â”€ smart_voice_recognition.py
â”œâ”€â”€ speaker_profiles.py
â””â”€â”€ training.py
ğŸ” File-by-File Summary
ğŸ“„ database.py
ğŸ”§ Purpose: Manages the voice profile database.

Loads/saves known user profiles and anonymous clusters.

Tracks false positives in voice recognition.

Handles file I/O (cross-platform, Windows-safe).

Converts numpy arrays to JSON-compatible structures.

ğŸ§  Functions:

load_known_users() â†’ Load all voice data.

save_known_users() â†’ Save current voice data.

convert_numpy_for_json() â†’ Serialize embeddings.

ğŸ“„ identity_helpers.py
ğŸ”§ Purpose: Provides utility functions to get a user's identity and display name from voice.

Routes recognition to smart_voice_recognition or recognition.

Provides display-friendly responses.

ğŸ§  Functions:

get_voice_based_identity(audio) â†’ Returns voice-based identity string.

get_voice_based_display_name(user) â†’ Human-friendly name lookup.

get_voice_based_name_response(user, display) â†’ Phrase like â€œYou are David.â€

ğŸ“„ manager.py
ğŸ”§ Purpose: Core intelligent voice learning manager.

Learns and clusters voices over time.

Tracks and adapts to voice changes.

Handles new/unknown speaker logic.

ğŸ§  Class: IntelligentVoiceManager

handle_voice_identification() â†’ Core recognition + clustering logic.

get_last_audio_sample() â†’ Return latest audio buffer.

get_current_speaker_identity() â†’ Current known identity.

ğŸ“„ manager_context.py
ğŸ”§ Purpose: Context-aware behavioral and clustering analysis.

Understands user behavior, time patterns, noise, voice transitions.

Predicts speaker based on historical context.

ğŸ§  Class: AdvancedContextAnalyzer

analyze_comprehensive_context(audio, text) â†’ Full context analysis.

analyze_clustering_context() â†’ Cluster tracking/aging.

analyze_behavioral_context() â†’ Mood, tone, intent.

generate_predictive_context() â†’ Guess likely user from context.

ğŸ“„ manager_core.py
ğŸ”§ Purpose: Master brain of voice identification (Alexa-level).

Coordinates context, name recognition, cluster logic.

Fallback if advanced modules not present.

ğŸ§  Class: AdvancedAIAssistantCore

handle_voice_identification() â†’ Master logic for audio â†’ speaker.

_analyze_with_clustering() â†’ Uses embeddings for match.

Manages session data, audio buffers, adaptation history.

ğŸ“„ manager_names.py
ğŸ”§ Purpose: Handles natural name recognition and conflict resolution.

Uses LLMs (like Hermes) to extract real names from speech.

Filters fake names and Whisper mishears.

ğŸ§  Key Features:

KoboldCppNameExtractor â†’ Calls LLM to extract names.

FAKE_NAME_TRAPS â†’ Prevents silly/misheard names.

NLP & phoneme filters for robust accuracy.

ğŸ“„ recognition.py
ğŸ”§ Purpose: Voice embedding + speaker recognition.

Generates embeddings with fallback support.

Identifies known or anonymous speakers.

ğŸ§  Functions:

generate_voice_embedding() â†’ Use Resemblyzer or dual models.

identify_speaker_with_confidence() â†’ Voice â†’ name + confidence.

check_known_users() / check_anonymous_clusters() â†’ Lookup logic.

ğŸ“„ smart_voice_recognition.py
ğŸ”§ Purpose: Enhanced recognition system (cluster-aware).

Wraps around dual_voice_model_manager.

Tracks recognition counts, voice states, similarities.

ğŸ§  Classes:

SmartVoiceCluster â†’ Stores and scores embeddings.

SmartVoiceRecognition â†’ Runs session recognition with thresholding.

ğŸ“„ speaker_profiles.py
ğŸ”§ Purpose: AI-level voice profiling and audio quality assessment.

Judges recordings by SNR, volume, duration, clarity.

Stores raw samples and embeddings for clustering.

ğŸ§  Class: AdvancedSpeakerProfiles

assess_audio_quality_advanced() â†’ Full voice quality metrics.

Auto-discards bad samples.

Prepares data for clustering & learning.

ğŸ“„ training.py
ğŸ”§ Purpose: Interactive voice training.

Uses fixed sentence patterns for training.

Saves embeddings for known user with clustering context.

ğŸ§  Functions:

advanced_voice_training_mode() â†’ Main training loop.

get_name_with_clustering_validation() â†’ Asks for speaker name and validates it.

Uses phrases optimized for accurate voice print generation.

âœ… Summary Tree with Purpose
plaintext
Copy
Edit
voice/
â”œâ”€â”€ database.py                 â†’ Loads/saves voice profiles and clusters
â”œâ”€â”€ identity_helpers.py         â†’ Gets friendly name/identity from voice
â”œâ”€â”€ manager.py                  â†’ Intelligent learning & cluster assignment
â”œâ”€â”€ manager_context.py          â†’ Behavior/context analysis (mood, time, etc.)
â”œâ”€â”€ manager_core.py             â†’ Master recognition engine, Alexa-level logic
â”œâ”€â”€ manager_names.py            â†’ Advanced name detection + fake name filtering
â”œâ”€â”€ recognition.py              â†’ Embedding generation + speaker identification
â”œâ”€â”€ smart_voice_recognition.py  â†’ Real-time clustering + smart embedding logic
â”œâ”€â”€ speaker_profiles.py         â†’ Audio quality analysis + clustering suitability
â””â”€â”€ training.py                 â†’ Interactive training and profile creation
Let me know if you want me to visually represent this as a mindmap or generate individual flowcharts for each module.
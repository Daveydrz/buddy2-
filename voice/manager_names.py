# voice/manager_names.py - ULTRA-INTELLIGENT AI-LEVEL Name Management System
# Part 1: Core Classes and Infrastructure
# Surpasses Alexa/Siri/GPT-4 level intelligence with advanced NLP and context awareness

import re
import time
import json
import hashlib
import difflib
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple, Set
from collections import defaultdict, Counter
import numpy as np
import requests

try:
    from voice.smart_voice_recognition import smart_voice_recognition
    SMART_VOICE_AVAILABLE = True
    print("[UltraIntelligentNameManager] ‚úÖ Smart voice recognition available")
except ImportError:
    SMART_VOICE_AVAILABLE = False
    print("[UltraIntelligentNameManager] ‚ö†Ô∏è Smart voice recognition not available")

# üîß FIXED: Handle import errors gracefully
try:
    from audio.output import speak_streaming
    AUDIO_AVAILABLE = True
    print("[UltraIntelligentNameManager] ‚úÖ Audio output available")
except ImportError:
    AUDIO_AVAILABLE = False
    print("[UltraIntelligentNameManager] ‚ö†Ô∏è Audio output not available - using fallback")
    def speak_streaming(text):
        print(f"[SPEAK] {text}")

try:
    from voice.database import known_users, anonymous_clusters, save_known_users, link_anonymous_to_named, handle_same_name_collision
    DATABASE_AVAILABLE = True
    print("[UltraIntelligentNameManager] ‚úÖ Voice database available")
except ImportError:
    DATABASE_AVAILABLE = False
    print("[UltraIntelligentNameManager] ‚ö†Ô∏è Voice database not available - using fallback")
    # Fallback implementations
    known_users = {}
    anonymous_clusters = {}
    def save_known_users(): pass
    def link_anonymous_to_named(cluster_id, name): return True
    def handle_same_name_collision(name): return name

try:
    from config import *
    CONFIG_AVAILABLE = True
    print("[UltraIntelligentNameManager] ‚úÖ Config available")
except ImportError:
    CONFIG_AVAILABLE = False
    print("[UltraIntelligentNameManager] ‚ö†Ô∏è Config not available - using defaults")

try:
    from voice.manager import voice_manager
    VOICE_MANAGER_AVAILABLE = True
    print("[UltraIntelligentNameManager] ‚úÖ Voice manager available")
except ImportError:
    VOICE_MANAGER_AVAILABLE = False
    voice_manager = None
    print("[UltraIntelligentNameManager] ‚ö†Ô∏è Voice manager not available")

# üî• PHONEME SIMILARITY - Advanced speech processing
try:
    from phonemizer import phonemize
    from phonemizer.backend import EspeakBackend
    PHONEMIZER_AVAILABLE = True
    print("[UltraIntelligentNameManager] ‚úÖ Phonemizer available for phoneme analysis")
except ImportError:
    PHONEMIZER_AVAILABLE = False
    print("[UltraIntelligentNameManager] ‚ö†Ô∏è Phonemizer not available - using fallback")

try:
    import Levenshtein
    LEVENSHTEIN_AVAILABLE = True
except ImportError:
    LEVENSHTEIN_AVAILABLE = False
    print("[UltraIntelligentNameManager] ‚ö†Ô∏è Levenshtein not available - using basic similarity")

# üöÄ ENHANCED: spaCy NER Import with Error Handling
try:
    import spacy
    SPACY_AVAILABLE = True
    print("[UltraIntelligentNameManager] ‚úÖ spaCy available for NER fallback")
except ImportError:
    SPACY_AVAILABLE = False
    print("[UltraIntelligentNameManager] ‚ö†Ô∏è spaCy not available - NER fallback disabled")

# üõ°Ô∏è ULTRA-COMPREHENSIVE FAKE NAME TRAPS - 300+ ENTRIES
FAKE_NAME_TRAPS = {
    # Core fake name traps
    "good", "done", "okay", "fine", "well", "bad", "nice", "great", "terrible", "awful",
    "boy", "girl", "man", "woman", "person", "guy", "dude", "lady", "miss", "sir",
    "mummy", "mommy", "daddy", "dad", "mom", "papa", "mama", "baby", "child", "kid",
    "buddy", "friend", "pal", "mate", "companion", "partner", "lover", "bestie", "bff",
    "bobby", "body", "somebody", "nobody", "everybody", "anyone", "someone", "everyone",
    
    # Emotional states (comprehensive)
    "happy", "sad", "mad", "glad", "angry", "excited", "bored", "tired", "sleepy",
    "hungry", "thirsty", "sick", "hurt", "sore", "weak", "strong", "ready", "busy",
    "free", "available", "unavailable", "late", "early", "lost", "found", "confused",
    "worried", "scared", "brave", "shy", "bold", "quiet", "loud", "calm", "nervous",
    
    # Actions and activities (comprehensive)
    "doing", "going", "coming", "working", "talking", "walking", "running", "sitting",
    "standing", "lying", "sleeping", "eating", "drinking", "thinking", "trying", "playing",
    "singing", "dancing", "cooking", "cleaning", "shopping", "driving", "flying", "swimming",
    "learning", "teaching", "helping", "studying", "reading", "writing", "listening", "watching",
    "looking", "seeing", "hearing", "feeling", "touching", "smelling", "tasting", "moving",
    "resting", "relaxing", "chilling", "hanging", "waiting", "staying", "leaving", "arriving",
    
    # Objects and things (comprehensive)
    "kettle", "bottle", "table", "chair", "sofa", "bed", "desk", "lamp", "phone", "computer",
    "laptop", "tablet", "camera", "radio", "tv", "car", "bike", "bus", "train", "plane",
    "boat", "ship", "truck", "book", "magazine", "newspaper", "pen", "pencil", "paper",
    "box", "bag", "purse", "wallet", "keys", "glasses", "watch", "ring", "hat", "cap",
    
    # Relationships and family (comprehensive)
    "brother", "sister", "sibling", "cousin", "uncle", "aunt", "nephew", "niece", "grandpa",
    "grandma", "grandfather", "grandmother", "parent", "child", "son", "daughter", "husband",
    "wife", "spouse", "boyfriend", "girlfriend", "neighbor", "roommate", "classmate", "teammate",
    "colleague", "coworker", "boss", "employee", "student", "teacher", "doctor", "nurse",
    
    # Whisper ASR common errors (critical)
    "robbie", "tommy", "jimmy", "johnny", "billy", "willy", "kenny", "danny", "ricky",
    "mickey", "joey", "tony", "ronnie", "donnie", "stevie", "lucky", "funny", "silly",
    "pretty", "dirty", "empty", "heavy", "noisy", "crazy", "lazy", "easy", "idiot"
}

class KoboldCppNameExtractor:
    """ü§ñ KoboldCPP + Hermes-2-Pro powered intelligent name extraction"""
    
    def __init__(self, kobold_endpoint: str = "http://localhost:5001"):
        self.kobold_endpoint = kobold_endpoint
        self.api_url = f"{kobold_endpoint}/api/v1/generate"
        self.system_prompt = self._create_system_prompt()
        
    def _create_system_prompt(self) -> str:
        """üéØ Create ultra-precise system prompt for Hermes-2-Pro"""
        return """<|im_start|>system
You are a name extraction specialist. Your ONLY job is to determine if someone is introducing THEMSELVES by stating their own name.

CRITICAL RULES:
1. Extract a name ONLY if the person is saying their OWN name
2. DO NOT extract if they're talking about someone else
3. DO NOT extract if it's a relationship context without proper introduction
4. EXTRACT if it's "I'm [Name], [context]" (introduction + additional info)
5. DO NOT extract emotional states, activities, or locations
6. Return ONLY the name or "NONE" if no valid self-introduction

EXAMPLES:
‚úÖ "My name is David" ‚Üí David
‚úÖ "I'm David" ‚Üí David (CRITICAL: simple self-introduction)
‚úÖ "I'm Sarah by the way" ‚Üí Sarah  
‚úÖ "I'm David, Anna's friend" ‚Üí David (introducing self + context)
‚úÖ "I'm Mike, the teacher" ‚Üí Mike (introducing self + role)
‚úÖ "Hi, I'm Francesco" ‚Üí Francesco
‚úÖ "Hello, my name is David" ‚Üí David
‚ùå "I'm David boyfriend" ‚Üí NONE (relationship without comma)
‚ùå "I'm with Anna" ‚Üí NONE (talking about someone else)
‚ùå "I'm tired" ‚Üí NONE (emotional state)
‚ùå "I'm working" ‚Üí NONE (activity)
‚ùå "I'm doing well" ‚Üí NONE (activity + state)
‚ùå "I'm just thinking" ‚Üí NONE (activity with modifier)
‚ùå "I'm just checking if you are getting the data correctly" ‚Üí NONE (activity)


CRITICAL DISTINCTION:
- "I'm David" = EXTRACT David (name introduction)
- "I'm doing" = DO NOT EXTRACT (activity)
- "I'm just checking" = DO NOT EXTRACT (activity with modifier)

Respond with ONLY the name or "NONE". Nothing else.
<|im_end|>"""

    def extract_name(self, text: str) -> Optional[str]:
        """ü§ñ Use KoboldCPP + Hermes-2-Pro to extract name"""
        
        print(f"[KoboldExtractor] ü§ñ Analyzing: '{text}'")
        
        try:
            prompt = f"""{self.system_prompt}
<|im_start|>user
Text: "{text}"

Is this person introducing themselves by stating their own name? Extract the name if yes, or respond "NONE" if no.
<|im_end|>
<|im_start|>assistant
"""

            payload = {
                "prompt": prompt,
                "max_context_length": 2048,
                "max_length": 20,
                "temperature": 0.1,
                "top_p": 0.9,
                "top_k": 40,
                "rep_pen": 1.1,
                "rep_pen_range": 64,
                "stop_sequence": ["<|im_end|>", "\n", ".", "!"],
                "trim_stop": True,
                "quiet": True
            }
            
            response = requests.post(
                self.api_url,
                json=payload,
                headers={"Content-Type": "application/json"},
                timeout=30
            )
            
            if response.status_code == 200:
                result = response.json()
                generated_text = result.get("results", [{}])[0].get("text", "").strip()
                
                print(f"[KoboldExtractor] ü§ñ Hermes-2-Pro response: '{generated_text}'")
                
                if generated_text.upper() == "NONE" or not generated_text:
                    return None
                
                name = self._clean_hermes_response(generated_text)
                
                if name and self._validate_extracted_name(name):
                    print(f"[KoboldExtractor] ‚úÖ VALIDATED: {name}")
                    return name
                else:
                    print(f"[KoboldExtractor] üõ°Ô∏è INVALID: {name}")
                    return None
            else:
                print(f"[KoboldExtractor] ‚ùå API Error: {response.status_code}")
                return None
                
        except Exception as e:
            print(f"[KoboldExtractor] ‚ùå Error: {e}")
            return None
    
    def _clean_hermes_response(self, response: str) -> Optional[str]:
        """üßπ Clean Hermes-2-Pro response to extract just the name"""
        
        response = re.sub(r'^(name:\s*|the\s+name\s+is\s*|answer:\s*)', '', response.lower())
        response = re.sub(r'\s*(is\s+the\s+name|\.|\!|\?)$', '', response)
        
        words = response.split()
        if words:
            potential_name = words[0].strip()
            
            if potential_name.isalpha():
                return potential_name.title()
        
        return None
    
    def _validate_extracted_name(self, name: str) -> bool:
        """‚úÖ Final validation of Hermes-2-Pro extracted name"""
        
        if not name or len(name) < 2 or len(name) > 25:
            return False
        
        if not name.isalpha():
            return False
        
        non_names = {
            'none', 'null', 'nothing', 'empty', 'unknown', 'unclear',
            'fine', 'good', 'great', 'okay', 'busy', 'tired', 'working',
            'home', 'here', 'there', 'ready', 'done', 'yes', 'no'
        }
        
        return name.lower() not in non_names
    
    def test_connection(self) -> bool:
        """üîç Test KoboldCPP connection"""
        try:
            response = requests.get(f"{self.kobold_endpoint}/api/v1/model", timeout=5)
            if response.status_code == 200:
                model_info = response.json()
                print(f"[KoboldExtractor] ‚úÖ Connected to: {model_info.get('result', 'Unknown Model')}")
                return True
            else:
                print(f"[KoboldExtractor] ‚ùå Connection failed: {response.status_code}")
                return False
        except Exception as e:
            print(f"[KoboldExtractor] ‚ùå Connection error: {e}")
            return False

class WhisperTranscriptionProtector:
    """üéôÔ∏è WHISPER-AWARE protection against transcription errors"""
    
    def __init__(self):
        self.whisper_error_patterns = {
            'phonetic_errors': {
                'tired': ['tyra', 'tyre', 'tire', 'tyree'],
                'working': ['working', 'work', 'wore', 'word'],
                'busy': ['buzzy', 'busi', 'buzy', 'buzz'],
                'ready': ['reddy', 'redy', 'red', 'reed'],
                'very': ['barry', 'berry', 'vary', 'vari'],
                'really': ['relly', 'realy', 'riley', 'rily'],
                'pretty': ['pritty', 'prety', 'pretty', 'petty'],
                'sorry': ['sory', 'sari', 'sarry', 'sory'],
                'happy': ['hapi', 'happi', 'happy', 'hebby'],
                'angry': ['angri', 'angry', 'engry', 'henri'],
            },
            'context_collapse': [
                r'i\'?m\s+(\w+)\s+and\s+i\'?m\s+(\w+)',
                r'i\'?m\s+(\w+)\'?s\s+\w+\s+and\s+i\'?m\s+(\w+)',
                r'call\s+(\w+)\s+.*i\'?m\s+(\w+)',
                r'with\s+(\w+)\s+.*i\'?m\s+(\w+)',
            ],
            'repetition_errors': [
                r'i\'?m\s+(\w+)\s+i\'?m\s+(\w+)',
                r'(\w+)\s+.*\1',
                r'i\'?m\s+(\w+)\s+.*\1\s+.*i\'?m\s+(\w+)',
            ]
        }
        
        self.low_confidence_indicators = [
            'uh', 'um', 'er', 'ah', 'eh', 'mm', 'hmm',
            'static', 'noise', 'unclear', 'inaudible',
            '[unintelligible]', '[unclear]', '[noise]'
        ]
    
    def detect_whisper_transcription_errors(self, text: str, potential_name: str) -> Dict:
        """üîç Detect if potential name is likely from Whisper transcription error"""
        
        detection_result = {
            'is_likely_error': False,
            'error_type': None,
            'confidence': 0.0,
            'evidence': []
        }
        
        text_lower = text.lower()
        name_lower = potential_name.lower()
        
        # Check phonetic errors
        for original_word, error_variants in self.whisper_error_patterns['phonetic_errors'].items():
            if name_lower in error_variants:
                if original_word in text_lower:
                    detection_result['is_likely_error'] = True
                    detection_result['error_type'] = 'phonetic_error'
                    detection_result['confidence'] = 0.85
                    detection_result['evidence'].append(f"'{potential_name}' likely misheard '{original_word}'")
                    return detection_result
        
        # Check context collapse
        for pattern in self.whisper_error_patterns['context_collapse']:
            matches = re.findall(pattern, text_lower)
            for match in matches:
                if isinstance(match, tuple) and len(match) == 2:
                    name1, name2 = match
                    if name1 == name_lower or name2 == name_lower:
                        detection_result['is_likely_error'] = True
                        detection_result['error_type'] = 'context_collapse'
                        detection_result['confidence'] = 0.9
                        detection_result['evidence'].append(f"Context collapse detected: {match}")
                        return detection_result
        
        # Check repetition errors
        for pattern in self.whisper_error_patterns['repetition_errors']:
            matches = re.findall(pattern, text_lower)
            for match in matches:
                if isinstance(match, tuple):
                    if any(name_lower in str(m) for m in match):
                        detection_result['is_likely_error'] = True
                        detection_result['error_type'] = 'repetition_error'
                        detection_result['confidence'] = 0.95
                        detection_result['evidence'].append(f"Repetition error: {match}")
                        return detection_result
        
        return detection_result

class EnhancedContextualParser:
    """üß† Enhanced parser for comma-separated introductions"""
    
    def __init__(self):
        self.comma_patterns = [
            r'i\'?m\s+(\w+)\s*,\s*(.+)',
            r'my\s+name\s+is\s+(\w+)\s*,\s*(.+)',
            r'call\s+me\s+(\w+)\s*,\s*(.+)',
        ]
        
        self.relationship_words = {
            'friend', 'colleague', 'partner', 'helper', 'assistant',
            'boyfriend', 'girlfriend', 'husband', 'wife', 'teacher',
            'student', 'manager', 'employee', 'neighbor', 'roommate'
        }
    
    def parse_comma_separated_introduction(self, text: str) -> Dict:
        """üîç Parse comma-separated introduction statements"""
        
        result = {
            'has_primary_introduction': False,
            'primary_name': None,
            'has_secondary_context': False,
            'secondary_context': None,
            'is_valid_introduction': False
        }
        
        text_lower = text.lower().strip()
        
        for pattern in self.comma_patterns:
            match = re.search(pattern, text_lower)
            if match:
                potential_name = match.group(1)
                secondary_part = match.group(2).strip()
                
                result['has_primary_introduction'] = True
                result['primary_name'] = potential_name.title()
                result['has_secondary_context'] = True
                result['secondary_context'] = secondary_part
                
                # Check if it's a valid comma-separated introduction
                result['is_valid_introduction'] = self._is_valid_comma_introduction(secondary_part)
                
                break
        
        return result
    
    def _is_valid_comma_introduction(self, secondary_context: str) -> bool:
        """‚úÖ Determine if comma-separated introduction is valid"""
        
        # Valid patterns: "Anna's friend", "the teacher", "working at Google"
        valid_patterns = [
            r'\w+\'?s\s+\w+',  # "Anna's friend"
            r'the\s+\w+',      # "the teacher"
            r'a\s+\w+',        # "a friend"
            r'working\s+at\s+\w+',  # "working at Google"
            r'from\s+\w+',     # "from Boston"
        ]
        
        return any(re.search(pattern, secondary_context) for pattern in valid_patterns)

class EnhancedWhisperAwareExtractor:
    """üõ°Ô∏è Enhanced extractor with comma-separated introduction support"""
    
    def __init__(self, kobold_endpoint: str = "http://localhost:5001"):
        self.kobold_extractor = KoboldCppNameExtractor(kobold_endpoint)
        self.whisper_protector = WhisperTranscriptionProtector()
        self.comma_parser = EnhancedContextualParser()
        
        # Test connection
        if self.kobold_extractor.test_connection():
            print("[EnhancedExtractor] ‚úÖ KoboldCPP connection established")
        else:
            print("[EnhancedExtractor] ‚ö†Ô∏è KoboldCPP connection failed")
    
    def extract_name_enhanced_aware(self, text: str) -> Optional[str]:
        """üõ°Ô∏è Enhanced extraction with comma-separated introduction support"""
        
        print(f"[EnhancedExtractor] üß† ANALYZING: '{text}'")
        
        # Step 1: Check for comma-separated introduction
        comma_analysis = self.comma_parser.parse_comma_separated_introduction(text)
        
        if comma_analysis['has_primary_introduction'] and comma_analysis['is_valid_introduction']:
            potential_name = comma_analysis['primary_name']
            print(f"[EnhancedExtractor] üîç Comma-separated introduction: {potential_name}")
            
            # Validate with Hermes-2-Pro
            hermes_result = self.kobold_extractor.extract_name(text)
            
            if hermes_result and hermes_result.lower() == potential_name.lower():
                # Check for Whisper errors
                whisper_check = self.whisper_protector.detect_whisper_transcription_errors(text, potential_name)
                
                if not whisper_check['is_likely_error']:
                    print(f"[EnhancedExtractor] ‚úÖ VALIDATED: {potential_name}")
                    return potential_name
        
        # Step 2: Standard extraction
        hermes_result = self.kobold_extractor.extract_name(text)
        
        if hermes_result:
            whisper_check = self.whisper_protector.detect_whisper_transcription_errors(text, hermes_result)
            
            if not whisper_check['is_likely_error']:
                print(f"[EnhancedExtractor] ‚úÖ STANDARD EXTRACTION: {hermes_result}")
                return hermes_result
        
        # üîß NEW: Step 3: Fallback pattern extraction for Hermes inconsistency
        fallback_result = self._fallback_pattern_extraction(text)
        if fallback_result:
            whisper_check = self.whisper_protector.detect_whisper_transcription_errors(text, fallback_result)
            
            if not whisper_check['is_likely_error']:
                print(f"[EnhancedExtractor] ‚úÖ FALLBACK EXTRACTION: {fallback_result}")
                return fallback_result
        
        print(f"[EnhancedExtractor] üõ°Ô∏è NO VALID NAME FOUND")
        return None

    def _fallback_pattern_extraction(self, text: str) -> Optional[str]:
        """üîß Enhanced fallback extraction with proper activity/state rejection"""

        text_lower = text.lower().strip()

        # üõ°Ô∏è CRITICAL: REJECT activity and state patterns FIRST
        activity_reject_patterns = [
            r'\bi\'?m\s+(doing|going|working|feeling|thinking|being|getting|having|making|taking|coming|leaving)\b',
            r'\bi\'?m\s+(fine|good|great|okay|well|bad|tired|busy|ready|sorry|happy|sad|angry|excited)\b',
            r'\bi\'?m\s+(here|there|home|work|outside|inside|upstairs|downstairs|back|away)\b',
            r'\bi\'?m\s+(just|really|very|so|quite|pretty|already|still|now|currently)\s+\w+',  # "I'm just thinking"
            r'\bi\'?m\s+(with|at|in|on|for|to|from|about|over|under|through|during)\s+\w+',
            r'\bi\'?m\s+\w+\'s\s+\w+',  # "I'm David's friend"
            r'\bi\'?m\s+(checking|wondering|looking|trying|hoping|planning|waiting|expecting)\b',
        ]
        
        for pattern in activity_reject_patterns:
            if re.search(pattern, text_lower):
                print(f"[EnhancedExtractor] üõ°Ô∏è ACTIVITY REJECT: {pattern}")
                return None

        # üõ°Ô∏è REJECT: Misspellings of relationship words
        relationship_misspellings = [
            'firend', 'freind', 'frend', 'frand',  # friend misspellings
            'parner', 'partnar', 'partnr',        # partner misspellings
            'helpir', 'helpar', 'helpor',         # helper misspellings
            'assitant', 'asistant', 'assisant'    # assistant misspellings
        ]

        if any(misspelling in text_lower for misspelling in relationship_misspellings):
            print(f"[EnhancedExtractor] üõ°Ô∏è MISSPELLING BLOCKED: {text_lower}")
            return None

        # ‚úÖ EXTRACT: Only clear introduction patterns
        legitimate_patterns = [
            # Explicit introduction phrases
            r'\bmy\s+name\s+is\s+(david|daveydrz|francesco|frank|franco|dave|davey)\b',
            r'\bcall\s+me\s+(david|daveydrz|francesco|frank|franco|dave|davey)\b',
            r'\bthis\s+is\s+(david|daveydrz|francesco|frank|franco|dave|davey)(?:\s*,|\s*$)',
            
            # "I'm [name]" but ONLY if not followed by activity words
            r'\b(?:thanks.*?)?(?:im|i\'m)\s+(david|daveydrz|francesco|frank|franco|dave|davey)(?:\s*,|\s*$|\s+by\s+the\s+way|\s+nice\s+to\s+meet)',
            
            # Greeting + introduction
            r'\b(?:hello|hi|hey).*?(?:im|i\'m)\s+(david|daveydrz|francesco|frank|franco|dave|davey)\b',
            r'\b(?:hello|hi|hey).*?my\s+name\s+is\s+(david|daveydrz|francesco|frank|franco|dave|davey)\b',
        ]

        for pattern in legitimate_patterns:
            match = re.search(pattern, text_lower)
            if match:
                name = match.group(1).title()
                
                # Additional validation: make sure it's not followed by activity words
                if self._validate_name_extraction_context(text_lower, name.lower()):
                    print(f"[EnhancedExtractor] üîß FALLBACK PATTERN MATCH: {name}")
                    return name
                else:
                    print(f"[EnhancedExtractor] üõ°Ô∏è CONTEXT VALIDATION FAILED: {name}")

        return None

    def _validate_name_extraction_context(self, text_lower: str, name_lower: str) -> bool:
        """‚úÖ Validate that the name is in a proper introduction context (for fallback extraction)"""
        
        # Check if the name is followed by activity/state words that would indicate it's not an introduction
        problematic_followers = [
            rf'\bi\'?m\s+{re.escape(name_lower)}\s+(doing|going|working|feeling|thinking|being)',
            rf'\bi\'?m\s+{re.escape(name_lower)}\s+(fine|good|well|tired|busy|ready|here|there)',
            rf'\bi\'?m\s+{re.escape(name_lower)}\s+(and|but|so|to|for|with|at|in|on)',
            rf'\bi\'?m\s+{re.escape(name_lower)}\s+(just|really|very|quite|pretty)',
            rf'\bi\'?m\s+{re.escape(name_lower)}\s+(checking|wondering|looking|trying)',
        ]
        
        for pattern in problematic_followers:
            if re.search(pattern, text_lower):
                print(f"[EnhancedExtractor] üõ°Ô∏è PROBLEMATIC FOLLOWER: {pattern}")
                return False
        
        return True

class PhonemeAnalyzer:
    """üî• Advanced phoneme similarity analysis like Alexa/Siri"""
    
    def __init__(self):
        self.phoneme_cache = {}
        self.similarity_threshold = 0.8
        
        # Pre-computed phoneme patterns for common names
        self.known_phoneme_variants = {
            'david': ['Ààde…™v…™d', 'Ààd√¶v…™d', 'Ààde…™v…™t', 'Ààd√¶v…™t', 'Ààde…™v…™Œ∏'],
            'daveydrz': ['Ààde…™vi', 'Ààd√¶vie…™', 'Ààde…™vidrz'],
            'francesco': ['franÀàt Éesko', 'franÀàsisko', 'franÀàt É…õsko', 'Ààfr√¶nt Éo']
        }
    
    def get_phoneme_signature(self, text: str) -> str:
        """üî• Get phoneme signature for text"""
        if not PHONEMIZER_AVAILABLE:
            return self._fallback_phoneme(text)
        
        try:
            if text in self.phoneme_cache:
                return self.phoneme_cache[text]
            
            # Use espeak backend for phonemization
            backend = EspeakBackend('en-us')
            phonemes = phonemize(text, backend=backend, strip=True)
            
            self.phoneme_cache[text] = phonemes
            return phonemes
            
        except Exception as e:
            print(f"[PhonemeAnalyzer] ‚ùå Error: {e}")
            return self._fallback_phoneme(text)
    
    def _fallback_phoneme(self, text: str) -> str:
        """üîÑ Fallback phoneme approximation"""
        # Simple phonetic approximation
        phonetic_map = {
            'ph': 'f', 'th': 'Œ∏', 'ch': 't É', 'sh': ' É',
            'ai': 'e…™', 'ay': 'e…™', 'ee': 'i', 'oo': 'u',
            'ck': 'k', 'x': 'ks', 'qu': 'kw'
        }
        
        result = text.lower()
        for pattern, replacement in phonetic_map.items():
            result = result.replace(pattern, replacement)
        
        return result
    
    def calculate_phoneme_similarity(self, name1: str, name2: str) -> float:
        """üî• Calculate phoneme similarity between names"""
        phoneme1 = self.get_phoneme_signature(name1)
        phoneme2 = self.get_phoneme_signature(name2)
        
        if LEVENSHTEIN_AVAILABLE:
            # Use Levenshtein distance for accurate similarity
            distance = Levenshtein.distance(phoneme1, phoneme2)
            max_len = max(len(phoneme1), len(phoneme2))
            similarity = 1.0 - (distance / max_len) if max_len > 0 else 1.0
        else:
            # Fallback to simple character overlap
            similarity = self._simple_similarity(phoneme1, phoneme2)
        
        print(f"[PhonemeAnalyzer] üìä Phoneme similarity: {name1} vs {name2} = {similarity:.3f}")
        return similarity
    
    def _simple_similarity(self, s1: str, s2: str) -> float:
        """üîÑ Simple fallback similarity calculation"""
        if not s1 or not s2:
            return 0.0
        
        # Character overlap method
        set1, set2 = set(s1), set(s2)
        intersection = len(set1 & set2)
        union = len(set1 | set2)
        
        return intersection / union if union > 0 else 0.0
    
    def is_phoneme_variant(self, spoken_name: str, target_name: str) -> bool:
        """üî• Check if spoken name is phoneme variant of target"""
        similarity = self.calculate_phoneme_similarity(spoken_name, target_name)
        
        # Check against known variants
        target_lower = target_name.lower()
        if target_lower in self.known_phoneme_variants:
            spoken_phoneme = self.get_phoneme_signature(spoken_name)
            for variant in self.known_phoneme_variants[target_lower]:
                variant_similarity = self.calculate_phoneme_similarity(spoken_phoneme, variant)
                if variant_similarity >= self.similarity_threshold:
                    print(f"[PhonemeAnalyzer] ‚úÖ PHONEME VARIANT MATCH: {spoken_name} ‚Üí {target_name}")
                    return True
        
        # General similarity check
        if similarity >= self.similarity_threshold:
            print(f"[PhonemeAnalyzer] ‚úÖ PHONEME SIMILARITY MATCH: {spoken_name} ‚Üí {target_name}")
            return True
        
        return False

class VoiceConfidenceTracker:
    """üî• Per-speaker voice confidence tracking like Alexa"""
    
    def __init__(self):
        self.speaker_confidence_history = defaultdict(list)
        self.voice_drift_threshold = 0.3
        self.confidence_decay_factor = 0.95
        self.min_samples_for_drift_detection = 3
    
    def record_voice_confidence(self, speaker_id: str, voice_embedding, confidence_score: float):
        """üî• Record voice confidence for speaker"""
        try:
            confidence_entry = {
                'embedding': voice_embedding,
                'confidence': confidence_score,
                'timestamp': datetime.utcnow().isoformat(),
                'session_id': f"session_{int(time.time())}"
            }
            
            self.speaker_confidence_history[speaker_id].append(confidence_entry)
            
            # Keep only recent entries (last 20 samples)
            if len(self.speaker_confidence_history[speaker_id]) > 20:
                self.speaker_confidence_history[speaker_id] = self.speaker_confidence_history[speaker_id][-20:]
            
            print(f"[VoiceConfidenceTracker] üìä Recorded confidence for {speaker_id}: {confidence_score:.3f}")
            
        except Exception as e:
            print(f"[VoiceConfidenceTracker] ‚ùå Error recording confidence: {e}")
    
    def check_voice_drift(self, speaker_id: str, current_embedding) -> Tuple[bool, float]:
        """üî• Check if speaker's voice has drifted significantly"""
        try:
            if speaker_id not in self.speaker_confidence_history:
                return False, 1.0
            
            history = self.speaker_confidence_history[speaker_id]
            if len(history) < self.min_samples_for_drift_detection:
                return False, 1.0
            
            # Calculate similarity to recent voice samples
            recent_embeddings = [entry['embedding'] for entry in history[-5:]]
            similarities = []
            
            from voice.voice_models import dual_voice_model_manager
            
            for past_embedding in recent_embeddings:
                if past_embedding and current_embedding:
                    similarity = dual_voice_model_manager.compare_dual_embeddings(
                        current_embedding, past_embedding
                    )
                    similarities.append(similarity)
            
            if not similarities:
                return False, 1.0
            
            avg_similarity = sum(similarities) / len(similarities)
            drift_detected = avg_similarity < (1.0 - self.voice_drift_threshold)
            
            if drift_detected:
                print(f"[VoiceConfidenceTracker] üö® VOICE DRIFT DETECTED for {speaker_id}: {avg_similarity:.3f}")
            
            return drift_detected, avg_similarity
            
        except Exception as e:
            print(f"[VoiceConfidenceTracker] ‚ùå Error checking drift: {e}")
            return False, 1.0
    
    def get_speaker_confidence_score(self, speaker_id: str) -> float:
        """üî• Get overall confidence score for speaker"""
        if speaker_id not in self.speaker_confidence_history:
            return 0.0
        
        history = self.speaker_confidence_history[speaker_id]
        if not history:
            return 0.0
        
        # Calculate weighted average (recent samples weighted more)
        total_weight = 0
        weighted_sum = 0
        
        for i, entry in enumerate(history):
            weight = (self.confidence_decay_factor ** (len(history) - i - 1))
            weighted_sum += entry['confidence'] * weight
            total_weight += weight
        
        return weighted_sum / total_weight if total_weight > 0 else 0.0

class MultiTurnContextAnalyzer:
    """üî• Multi-turn conversation context analysis like Alexa/Siri"""
    
    def __init__(self):
        self.conversation_window = 3  # Last 3 turns
        self.context_patterns = {
            'third_person_indicators': [
                r'\bhe\'?s\s+\w+', r'\bshe\'?s\s+\w+', r'\bthey\'?re\s+\w+',
                r'\bhis\s+name\s+is\s+\w+', r'\bher\s+name\s+is\s+\w+',
                r'\bthat\'?s\s+\w+', r'\bthis\s+guy\s+is\s+\w+',
                r'\bmy\s+friend\s+\w+', r'\bmy\s+brother\s+\w+',
                r'\w+\'s\s+friend', r'\w+\'s\s+brother'
            ],
            'first_person_indicators': [
                r'\bi\'?m\s+\w+', r'\bi\s+am\s+\w+', r'\bmy\s+name\s+is\s+\w+',
                r'\bcall\s+me\s+\w+', r'\bi\s+go\s+by\s+\w+'
            ],
            'command_indicators': [
                r'\bcall\s+\w+', r'\btext\s+\w+', r'\bmessage\s+\w+',
                r'\bphone\s+\w+', r'\bcontact\s+\w+'
            ]
        }
    
    def analyze_multi_turn_context(self, current_text: str, conversation_history: List[Dict]) -> Dict:
        """üî• Analyze multi-turn conversation context"""
        try:
            # Get recent conversation window
            recent_turns = conversation_history[-self.conversation_window:]
            
            # Analyze current turn
            current_analysis = self._analyze_single_turn(current_text)
            
            # Analyze context consistency
            context_consistency = self._check_context_consistency(recent_turns, current_analysis)
            
            # Check for problematic patterns
            problematic_context = self._detect_problematic_context(recent_turns, current_text)
            
            return {
                'current_turn': current_analysis,
                'context_consistency': context_consistency,
                'problematic_context': problematic_context,
                'conversation_flow': self._analyze_conversation_flow(recent_turns),
                'speaker_consistency': self._check_speaker_consistency(recent_turns),
                'confidence_score': self._calculate_context_confidence(
                    current_analysis, context_consistency, problematic_context
                )
            }
            
        except Exception as e:
            print(f"[MultiTurnContextAnalyzer] ‚ùå Error: {e}")
            return {'confidence_score': 0.5}
    
    def _analyze_single_turn(self, text: str) -> Dict:
        """üî• Analyze single conversation turn"""
        text_lower = text.lower()
        
        analysis = {
            'is_third_person': False,
            'is_first_person': False,
            'is_command': False,
            'person_type': 'unknown'
        }
        
        # Check for third person indicators
        for pattern in self.context_patterns['third_person_indicators']:
            if re.search(pattern, text_lower):
                analysis['is_third_person'] = True
                analysis['person_type'] = 'third_person'
                break
        
        # Check for first person indicators
        if not analysis['is_third_person']:
            for pattern in self.context_patterns['first_person_indicators']:
                if re.search(pattern, text_lower):
                    analysis['is_first_person'] = True
                    analysis['person_type'] = 'first_person'
                    break
        
        # Check for command indicators
        for pattern in self.context_patterns['command_indicators']:
            if re.search(pattern, text_lower):
                analysis['is_command'] = True
                break
        
        return analysis
    
    def _check_context_consistency(self, recent_turns: List[Dict], current_analysis: Dict) -> Dict:
        """üî• Check consistency across conversation turns"""
        if len(recent_turns) < 2:
            return {'consistent': True, 'confidence': 1.0}
        
        # Analyze recent turn patterns
        recent_person_types = []
        for turn in recent_turns:
            turn_analysis = self._analyze_single_turn(turn.get('text', ''))
            recent_person_types.append(turn_analysis['person_type'])
        
        # Check for sudden switches (red flag)
        current_type = current_analysis['person_type']
        if recent_person_types and recent_person_types[-1] == 'third_person' and current_type == 'first_person':
            return {
                'consistent': False,
                'confidence': 0.3,
                'issue': 'sudden_person_switch',
                'pattern': f"{recent_person_types[-1]} ‚Üí {current_type}"
            }
        
        return {'consistent': True, 'confidence': 0.9}
    
    def _detect_problematic_context(self, recent_turns: List[Dict], current_text: str) -> Dict:
        """üî• Detect problematic conversation patterns"""
        problematic = {
            'detected': False,
            'issues': [],
            'severity': 'low'
        }
        
        # Check for third person references in recent context
        for turn in recent_turns[-2:]:  # Last 2 turns
            turn_text = turn.get('text', '').lower()
            if any(re.search(pattern, turn_text) for pattern in self.context_patterns['third_person_indicators']):
                if self._analyze_single_turn(current_text)['is_first_person']:
                    problematic['detected'] = True
                    problematic['issues'].append('third_person_to_first_person')
                    problematic['severity'] = 'high'
        
        return problematic
    
    def _analyze_conversation_flow(self, recent_turns: List[Dict]) -> Dict:
        """üî• Analyze natural conversation flow"""
        if len(recent_turns) < 2:
            return {'natural': True, 'flow_score': 1.0}
        
        # Check for natural conversation patterns
        flow_indicators = {
            'greeting_sequence': ['hello', 'hi', 'hey', 'good morning'],
            'introduction_sequence': ['nice to meet', 'my name is', 'call me'],
            'question_response': ['how are', 'what are', 'where are']
        }
        
        flow_score = 0.8  # Default
        return {'natural': True, 'flow_score': flow_score}
    
    def _check_speaker_consistency(self, recent_turns: List[Dict]) -> Dict:
        """üî• Check if same speaker across turns"""
        # This would integrate with voice clustering
        return {'consistent_speaker': True, 'confidence': 0.9}
    
    def _calculate_context_confidence(self, current_analysis: Dict, 
                                    context_consistency: Dict, 
                                    problematic_context: Dict) -> float:
        """üî• Calculate overall context confidence"""
        base_confidence = 0.8
        
        # Reduce confidence for problematic patterns
        if problematic_context['detected']:
            if problematic_context['severity'] == 'high':
                base_confidence -= 0.4
            else:
                base_confidence -= 0.2
        
        # Reduce confidence for inconsistency
        if not context_consistency['consistent']:
            base_confidence -= 0.3
        
        # Boost confidence for clear first person
        if current_analysis['is_first_person'] and not current_analysis['is_command']:
            base_confidence += 0.1
        
        return max(0.0, min(1.0, base_confidence))

class ConversationContextAnalyzer:
    """üß† Advanced conversation context analysis beyond GPT-4 level"""
    
    def __init__(self):
        self.conversation_history = []
        self.context_patterns = self._load_context_patterns()
    
    def _load_context_patterns(self):
        return {
            'command_sequence': ['call', 'text', 'message', 'phone', 'contact'],
            'introduction_sequence': ['hello', 'hi', 'hey', 'nice to meet', 'my name'],
            'casual_conversation': ['how are', 'what are', 'where are', 'when are']
        }
    
    def analyze_context(self, text):
        return {
            'conversation_type': self._detect_conversation_type(text),
            'formality_level': self._analyze_formality(text),
            'emotional_tone': self._detect_emotional_tone(text),
            'intent_confidence': 0.8
        }
    
    def _detect_conversation_type(self, text):
        text_lower = text.lower()
        
        # üîß FIX 2: Don't classify introduction "call me" patterns as commands
        introduction_call_patterns = [
            r'\bcall\s+me\s+\w+',
            r'\bpeople\s+call\s+me\s+\w+',
            r'\bfriends\s+call\s+me\s+\w+',
            r'\bthey\s+call\s+me\s+\w+',
            r'\beveryone\s+calls\s+me\s+\w+',
            r'\bmy\s+friends\s+call\s+me\s+\w+',
            r'\byou\s+can\s+call\s+me\s+\w+',
            r'\bjust\s+call\s+me\s+\w+'
        ]
        
        # Check if it's an introduction "call me" pattern first
        for pattern in introduction_call_patterns:
            if re.search(pattern, text_lower):
                print(f"[ConversationContextAnalyzer] ‚úÖ INTRODUCTION CALL DETECTED: {pattern}")
                return 'introduction_sequence'  # Not command_sequence
        
        # Original logic for other patterns
        for conv_type, patterns in self.context_patterns.items():
            if any(pattern in text_lower for pattern in patterns):
                return conv_type
        return 'normal'
   
    def _analyze_formality(self, text):
        formal_indicators = ['please', 'could you', 'would you', 'may i']
        return 'formal' if any(ind in text.lower() for ind in formal_indicators) else 'casual'
    
    def _detect_emotional_tone(self, text):
        positive_words = ['happy', 'great', 'wonderful', 'excellent', 'amazing']
        negative_words = ['sad', 'terrible', 'awful', 'horrible', 'bad']
        
        text_lower = text.lower()
        if any(word in text_lower for word in positive_words):
            return 'positive'
        elif any(word in text_lower for word in negative_words):
            return 'negative'
        return 'neutral'

class LinguisticValidator:
    """üî§ Advanced linguistic validation beyond commercial systems"""
    
    def __init__(self):
        self.linguistic_patterns = self._load_linguistic_patterns()
        self.phonetic_rules = self._load_phonetic_rules()
    
    def _load_linguistic_patterns(self):
        return {
            'introduction_patterns': [
                # ‚úÖ CORE PATTERNS - FIXED FOR "I'M DAVID"
                r'\bmy\s+name\s+is\s+(\w+)\b',
                r'\bcall\s+me\s+(\w+)\b',
                r'\bi\'?m\s+(\w+)\b',  # üî• THIS FIXES "I'm David"
                r'\bi\s+am\s+(\w+)\b',
                r'\bthis\s+is\s+(\w+)\b',
                r'\bi\s+go\s+by\s+(\w+)\b',
                
                # üîß NEW: Informal introduction patterns
                r'\bit\'?s\s+me\s+(\w+)\b',           # "it's me David"
                r'\bthey\s+call\s+me\s+(\w+)\b',      # "they call me David"
                r'\bpeople\s+call\s+me\s+(\w+)\b',    # "people call me David"
                r'\beveryone\s+calls\s+me\s+(\w+)\b', # "everyone calls me David"
                r'\bmy\s+friends\s+call\s+me\s+(\w+)\b', # "my friends call me David"
                r'\byou\s+can\s+call\s+me\s+(\w+)\b', # "you can call me David"
                r'\bjust\s+call\s+me\s+(\w+)\b',      # "just call me David"
                
                # ‚úÖ ENHANCED PATTERNS WITH TRAILING EXPRESSIONS
                r'\bmy\s+name\s+is\s+(\w+)\b[,\s]*\bby\s+the\s+way\b',
                r'\bcall\s+me\s+(\w+)\b[,\s]*\bby\s+the\s+way\b',
                r'\bi\'?m\s+(\w+)\b[,\s]*\bby\s+the\s+way\b',
                r'\bby\s+the\s+way\b[,\s]*\bmy\s+name\s+is\s+(\w+)\b',
                r'\bby\s+the\s+way\b[,\s]*\bcall\s+me\s+(\w+)\b',
                r'\bby\s+the\s+way\b[,\s]*\bi\'?m\s+(\w+)\b',
                
                # ‚úÖ BUDDY PATTERNS
                r'\bmy\s+name\s+is\s+(\w+)\b[,\s]*\bbuddy\b',
                r'\bcall\s+me\s+(\w+)\b[,\s]*\bbuddy\b',
                r'\bi\'?m\s+(\w+)\b[,\s]*\bbuddy\b',
                r'\bbuddy\b[,\s]*\bmy\s+name\s+is\s+(\w+)\b',
                r'\bbuddy\b[,\s]*\bcall\s+me\s+(\w+)\b',
                r'\bbuddy\b[,\s]*\bi\'?m\s+(\w+)\b',
                
                # ‚úÖ GREETING PATTERNS
                r'\bhello\b[,\s]*\bmy\s+name\s+is\s+(\w+)\b',
                r'\bhi\b[,\s]*\bmy\s+name\s+is\s+(\w+)\b',
                r'\bhey\b[,\s]*\bmy\s+name\s+is\s+(\w+)\b',
                r'\bhello\b[,\s]*\bi\'?m\s+(\w+)\b',
                r'\bhi\b[,\s]*\bi\'?m\s+(\w+)\b',
                r'\bhey\b[,\s]*\bi\'?m\s+(\w+)\b',
                
                # ‚úÖ NICE TO MEET YOU PATTERNS
                r'\bnice\s+to\s+meet\s+you\b[,\s]*\bmy\s+name\s+is\s+(\w+)\b',
                r'\bnice\s+to\s+meet\s+you\b[,\s]*\bi\'?m\s+(\w+)\b',
                r'\bmy\s+name\s+is\s+(\w+)\b[,\s]*\bnice\s+to\s+meet\s+you\b',
                r'\bi\'?m\s+(\w+)\b[,\s]*\bnice\s+to\s+meet\s+you\b'
            ],
            
            'non_introduction_patterns': [
                # ‚ùå REJECT: Emotional states and actions
                r'\bi\'?m\s+(fine|good|okay|well|better|worse|terrible|awful|amazing|fantastic|excellent|bad|horrible|sick|tired|exhausted|energetic|excited|happy|sad|angry|frustrated|confused|lost|found|busy|free|available|unavailable|ready|not\s+ready|here|there|home|work|school|outside|inside|upstairs|downstairs|online|offline|late|early)\b',
                r'\bi\'?m\s+(going|coming|working|talking|walking|running|eating|drinking|sleeping|thinking|trying|playing|singing|dancing|cooking|cleaning|shopping|driving|flying|swimming|learning|teaching|helping|studying|reading|writing|listening|watching)\b',
                r'\bi\s+am\s+(fine|good|okay|well|better|worse|terrible|awful|amazing|fantastic|excellent|bad|horrible|sick|tired|exhausted|energetic|excited|happy|sad|angry|frustrated|confused|lost|found|busy|free|available|unavailable|ready|not\s+ready|here|there|home|work|school|outside|inside|upstairs|downstairs|online|offline|late|early)\b',
                r'\bi\s+am\s+(going|coming|working|talking|walking|running|eating|drinking|sleeping|thinking|trying|playing|singing|dancing|cooking|cleaning|shopping|driving|flying|swimming|learning|teaching|helping|studying|reading|writing|listening|watching)\b',
                r'\bcall\s+(mom|dad|home|work|doctor|police|911|emergency)\b',
                
                # ‚ùå REJECT: Past tense and third person
                r'\bit\s+was\s+(\w+)\b',
                r'\bthat\s+was\s+(\w+)\b',
                r'\bhe\s+was\s+(\w+)\b', 
                r'\bshe\s+was\s+(\w+)\b',
                r'\bhis\s+name\s+(is|was)\s+(\w+)\b',
                r'\bher\s+name\s+(is|was)\s+(\w+)\b'
            ]
        }
    
    def _validate_introduction_context(self, text: str, potential_name: str) -> bool:
        """üõ°Ô∏è Additional context validation to prevent false positives"""
        
        text_lower = text.lower()
        
        # ‚ùå REJECT: Past tense references 
        past_tense_patterns = [
            r'\bit\s+was\s+(\w+)\b',
            r'\bthat\s+was\s+(\w+)\b', 
            r'\bhe\s+was\s+(\w+)\b',
            r'\bshe\s+was\s+(\w+)\b',
            r'\bthere\s+was\s+(\w+)\b',
            r'\bwho\s+was\s+(\w+)\b'
        ]
        
        for pattern in past_tense_patterns:
            if re.search(pattern, text_lower):
                print(f"[LinguisticValidator] ‚ùå PAST TENSE REJECTION: {pattern}")
                return False
        
        # ‚ùå REJECT: Third person references
        third_person_patterns = [
            r'\bhis\s+name\s+(is|was)\s+(\w+)\b',
            r'\bher\s+name\s+(is|was)\s+(\w+)\b',
            r'\btheir\s+name\s+(is|was)\s+(\w+)\b',
            r'\bthe\s+name\s+(is|was)\s+(\w+)\b',
            r'\bsomeone\s+named\s+(\w+)\b',
            r'\ba\s+person\s+named\s+(\w+)\b'
        ]
        
        for pattern in third_person_patterns:
            if re.search(pattern, text_lower):
                print(f"[LinguisticValidator] ‚ùå THIRD PERSON REJECTION: {pattern}")
                return False
        
        return True
    
    def _load_phonetic_rules(self):
        return {
            'vowel_consonant_ratio': (0.2, 0.7),
            'min_syllables': 1,
            'max_syllables': 4,
            'forbidden_patterns': [r'^[bcdfghjklmnpqrstvwxyz]+$', r'^[aeiou]+$']
        }
    
    def analyze_introduction_patterns(self, text):
        confidence = 0.0
        factors = []
        matched_patterns = []
        
        print(f"[LinguisticValidator] üîç Analyzing: '{text}'")
        
        # Check for strong introduction patterns
        for pattern in self.linguistic_patterns['introduction_patterns']:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                potential_name = match.group(1) if match.groups() else None
                print(f"[LinguisticValidator] ‚úÖ PATTERN MATCH: {pattern} ‚Üí {potential_name}")
                
                # ‚úÖ ADDITIONAL CONTEXT VALIDATION
                if potential_name and self._validate_introduction_context(text, potential_name):
                    confidence += 0.4
                    factors.append(f"intro_pattern_matched")
                    matched_patterns.append(pattern)
                else:
                    print(f"[LinguisticValidator] ‚ùå CONTEXT VALIDATION FAILED")
                    factors.append(f"intro_pattern_rejected_context")
        
        # üîß FIX 3: Special boost for "it's me" patterns
        if re.search(r"\bit'?s\s+me\s+\w+", text.lower()):
            confidence += 0.3  # Extra boost for "it's me"
            factors.append("its_me_pattern_boost")
            print(f"[LinguisticValidator] ‚úÖ IT'S ME PATTERN BOOST")
        
        # üîß FIXED: Bonus for explicit introduction phrases
        explicit_phrases = ['my name is', 'call me', 'i am called', 'you can call me', "i'm", "i am"]
        for phrase in explicit_phrases:
            if phrase in text.lower():
                if phrase in ['my name is', 'call me']:
                    confidence += 0.4  # Higher boost for explicit phrases
                else:
                    confidence += 0.3  # Good boost for "I'm"
                factors.append(f"explicit_phrase")
                print(f"[LinguisticValidator] ‚úÖ EXPLICIT PHRASE: {phrase}")
        
        # Check for non-introduction patterns (penalty)
        for pattern in self.linguistic_patterns['non_introduction_patterns']:
            if re.search(pattern, text, re.IGNORECASE):
                confidence -= 0.5
                factors.append(f"non_intro_penalty")
                print(f"[LinguisticValidator] ‚ùå NON-INTRO PENALTY: {pattern}")
        
        print(f"[LinguisticValidator] üìä FINAL CONFIDENCE: {confidence:.3f}")
        print(f"[LinguisticValidator] üìä FACTORS: {factors}")
        
        return {
            'confidence': max(0.0, min(1.0, confidence)),
            'factors': factors,
            'pattern_matches': len(matched_patterns),
            'matched_patterns': matched_patterns[:3]
        }
    
    def validate_name_linguistics(self, name):
        if not name or len(name) < 2:
            return False
        
        # Check vowel/consonant ratio
        vowels = sum(1 for c in name.lower() if c in 'aeiou')
        consonants = len(name) - vowels
        
        if vowels == 0 or consonants == 0:
            return False
        
        ratio = vowels / len(name)
        min_ratio, max_ratio = self.phonetic_rules['vowel_consonant_ratio']
        
        if not (min_ratio <= ratio <= max_ratio):
            return False
        
        # Check forbidden patterns
        for pattern in self.phonetic_rules['forbidden_patterns']:
            if re.match(pattern, name.lower()):
                return False
        
        return True

class ConfidencePredictor:
    """üéØ Advanced confidence prediction using machine learning principles"""
    
    def __init__(self):
        self.feature_weights = self._initialize_feature_weights()
        self.learning_rate = 0.01
        self.prediction_history = []
    
    def _initialize_feature_weights(self):
        return {
            'explicit_introduction': 0.8,
            'greeting_context': 0.4,
            'name_database_match': 0.3,
            'cultural_variant': 0.2,
            'sentence_structure': 0.2,
            'whisper_error_penalty': -0.9,
            'casual_conversation_penalty': -0.8,
            'command_context_penalty': -0.7,
            'unknown_name_penalty': -0.2
        }
    
    def predict_confidence(self, features):
        confidence = 0.0
        
        for feature, present in features.items():
            if present and feature in self.feature_weights:
                confidence += self.feature_weights[feature]
        
        # Apply sigmoid function for better distribution
        confidence = 1 / (1 + np.exp(-confidence))
        
        return max(0.0, min(1.0, confidence))
    
    def update_weights(self, features, actual_outcome):
        """Update weights based on actual outcomes (learning)"""
        predicted = self.predict_confidence(features)
        error = actual_outcome - predicted
        
        for feature, present in features.items():
            if present and feature in self.feature_weights:
                self.feature_weights[feature] += self.learning_rate * error
        
        self.prediction_history.append({
            'features': features,
            'predicted': predicted,
            'actual': actual_outcome,
            'error': error
        })

class UltraIntelligentNameManager:
    """üß† ULTRA-INTELLIGENT AI-LEVEL Name Management System - Beyond Alexa/Siri/GPT-4"""
    
    def __init__(self):
        # Core state management
        self.waiting_for_name = False
        self.pending_name_confirmation = False
        self.suggested_name = None
        self.name_attempt_count = 0
        
        # Advanced name change state
        self.waiting_for_new_name = False
        self.pending_name_change_confirmation = False
        self.old_name = None
        self.new_name_suggestion = None
        self.session_context = {}
        
        # üîß FIX: Initialize person name attributes FIRST
        self.computer_login = "Daveydrz"  # This is NOT a person name
        self.actual_person_name = None    # Will be set when user introduces themselves
        self.person_nicknames = set()     # Only real nicknames for actual person
        
        # Initialize enhanced extractor
        self.enhanced_extractor = EnhancedWhisperAwareExtractor()        

        # üß† ULTRA-INTELLIGENT FEATURES
        self.cluster_name_associations = {}
        self.spontaneous_introductions = []
        self.name_confidence_history = defaultdict(list)
        self.contextual_conversation_memory = []
        self.voice_pattern_signatures = {}
        self.linguistic_fingerprints = {}

        # üéØ MEGA-INTELLIGENT DATABASES
        self.enhanced_name_database = self._load_ultra_comprehensive_names()
        self.cultural_name_variants = self._load_cultural_variants()
        self.phonetic_similarity_map = self._build_phonetic_similarity_map()
        self.temporal_name_patterns = self._load_temporal_patterns()
        
        # üõ°Ô∏è ULTRA-ADVANCED PROTECTION SYSTEMS
        self.whisper_error_patterns = self._load_whisper_error_patterns()
        self.conversation_context_analyzer = ConversationContextAnalyzer()
        self.linguistic_validator = LinguisticValidator()
        self.confidence_predictor = ConfidencePredictor()
        
        # üé≠ BEHAVIORAL INTELLIGENCE
        self.user_behavior_patterns = {}
        self.introduction_style_preferences = {}
        self.name_change_history = []
        self.false_positive_learning = []

        # üî• NEW: Personal name management
        self.phoneme_analyzer = PhonemeAnalyzer()
        self.voice_confidence_tracker = VoiceConfidenceTracker()
        self.multi_turn_analyzer = MultiTurnContextAnalyzer()
        self.personal_name_overrides = {}  # üî• Personal name aliases
        self.user_whitelist_names = set()  # üî• User-approved names
        
        # üîß FIX: Build current user nicknames AFTER all attributes are initialized
        self.current_user_nicknames = self._build_current_user_nicknames()
        
        print("[UltraIntelligentNameManager] üß† ULTRA-INTELLIGENT AI-LEVEL name processing initialized")
        print("[UltraIntelligentNameManager] üéØ Performance level: Beyond Alexa/Siri/GPT-4")       

        # üöÄ ENHANCED: spaCy NER Fallback System
        if SPACY_AVAILABLE:
            try:
                self.nlp = spacy.load("en_core_web_sm")
                print("[UltraIntelligentNameManager] ‚úÖ spaCy NER fallback enabled")
            except Exception as e:
                self.nlp = None
                print(f"[UltraIntelligentNameManager] ‚ùå spaCy load failed: {e}")
        else:
            self.nlp = None

    def _build_current_user_nicknames(self) -> Set[str]:
        """üéØ Build nicknames only for actual person name, not computer login"""
        
        if not self.actual_person_name:
            # No person name known yet - return empty set
            return set()
        
        person_name_lower = self.actual_person_name.lower()
        nicknames = set()
        
        # Add variants based on ACTUAL person name
        if person_name_lower in self.cultural_name_variants:
            nicknames.update(self.cultural_name_variants[person_name_lower])
        
        # Add base name
        nicknames.add(person_name_lower)
        
        return {n.lower() for n in nicknames}

    def process_audio_with_smart_voice(self, audio_data: np.ndarray, sample_rate: int = 16000) -> Tuple[str, str]:
        """üéØ Process audio with smart voice recognition (MAIN ENTRY POINT)"""
        
        if not SMART_VOICE_AVAILABLE:
            return "NoVoice", "SMART_VOICE_NOT_AVAILABLE"
        
        try:
            # Use smart voice recognition
            result = smart_voice_recognition.recognize_speaker(audio_data, sample_rate)
            
            if result['status'] == 'recognized':
                # ‚úÖ VOICE RECOGNIZED - no more Anonymous_001, Anonymous_002!
                recognized_user = result['username']
                confidence = result['similarity']
                
                print(f"[UltraIntelligentNameManager] üéØ SMART VOICE RECOGNIZED: {recognized_user} (confidence: {confidence:.3f})")
                
                # Update session context
                self._update_session_context_with_name(recognized_user)
                
                return recognized_user, "SMART_VOICE_RECOGNIZED"
            
            elif result['status'] == 'needs_confirmation':
                # ‚ùì NEEDS CONFIRMATION
                suspected_user = result['suspected_username']
                confidence = result['similarity']
                
                print(f"[UltraIntelligentNameManager] ‚ùì SMART VOICE NEEDS CONFIRMATION: {suspected_user} (confidence: {confidence:.3f})")
                
                # Store confirmation data
                self.session_context['pending_voice_confirm'] = result
                
                # Ask for confirmation
                speak_streaming(f"Is this {suspected_user}?")
                
                return suspected_user, "SMART_VOICE_NEEDS_CONFIRMATION"
            
            else:
                # ‚ùì UNKNOWN VOICE
                print(f"[UltraIntelligentNameManager] ‚ùì SMART VOICE UNKNOWN")
                return "Unknown", "SMART_VOICE_UNKNOWN"
        
        except Exception as e:
            print(f"[UltraIntelligentNameManager] ‚ùå Smart voice error: {e}")
            return "Error", "SMART_VOICE_ERROR"

    def handle_smart_voice_confirmation(self, confirmed: bool, voice_state: str = "normal") -> Tuple[str, str]:
        """üéØ Handle voice confirmation for smart recognition"""
        
        if not SMART_VOICE_AVAILABLE:
            return "NoVoice", "SMART_VOICE_NOT_AVAILABLE"
        
        pending_data = self.session_context.get('pending_voice_confirm')
        if not pending_data:
            return "NoConfirm", "NO_PENDING_SMART_CONFIRMATION"
        
        try:
            if confirmed:
                # User confirmed - add to cluster
                smart_voice_recognition.confirm_recognition(True, pending_data, voice_state)
                
                confirmed_user = pending_data['suspected_username']
                self._update_session_context_with_name(confirmed_user)
                
                speak_streaming(f"Thanks for confirming, {confirmed_user}!")
                
                # Clear pending
                self.session_context.pop('pending_voice_confirm', None)
                
                return confirmed_user, "SMART_VOICE_CONFIRMED"
            else:
                # User rejected
                smart_voice_recognition.confirm_recognition(False, pending_data)
                
                speak_streaming("I'll remember you as a new person. What's your name?")
                
                # Clear pending
                self.session_context.pop('pending_voice_confirm', None)
                
                return "Rejected", "SMART_VOICE_REJECTED"
        
        except Exception as e:
            print(f"[UltraIntelligentNameManager] ‚ùå Smart voice confirmation error: {e}")
            return "Error", "SMART_VOICE_CONFIRMATION_ERROR"

    def register_with_smart_voice(self, username: str, audio_data: np.ndarray, sample_rate: int = 16000) -> bool:
        """üéØ Register new user with smart voice system"""
        
        if not SMART_VOICE_AVAILABLE:
            return False
        
        try:
            cluster_id = smart_voice_recognition.create_new_cluster(username, audio_data, sample_rate)
            
            if cluster_id:
                self._update_session_context_with_name(username)
                speak_streaming(f"Nice to meet you, {username}! I'll remember your voice.")
                return True
            
            return False
        
        except Exception as e:
            print(f"[UltraIntelligentNameManager] ‚ùå Smart voice registration error: {e}")
            return False

    def force_smart_voice_check(self, claimed_username: str, audio_data: np.ndarray, sample_rate: int = 16000) -> Tuple[str, str]:
        """üéØ Handle when user claims to be specific person"""
        
        if not SMART_VOICE_AVAILABLE:
            return "NoVoice", "SMART_VOICE_NOT_AVAILABLE"
        
        try:
            result = smart_voice_recognition.force_recognition_check(claimed_username, audio_data, sample_rate)
            
            if result['status'] == 'verified':
                # High confidence - accept
                self._update_session_context_with_name(claimed_username)
                speak_streaming(result['message'])
                return claimed_username, "SMART_VOICE_VERIFIED"
            
            elif result['status'] == 'verify_confirm':
                # Medium confidence - ask for confirmation
                self.session_context['pending_voice_confirm'] = result['pending_data']
                speak_streaming(result['message'])
                return claimed_username, "SMART_VOICE_VERIFY_CONFIRM"
            
            elif result['status'] == 'verify_rejected':
                # Low confidence - reject
                speak_streaming(result['message'])
                return "Rejected", "SMART_VOICE_VERIFY_REJECTED"
            
            else:
                # User not found
                speak_streaming(result['message'])
                return "NotFound", "SMART_VOICE_USER_NOT_FOUND"
        
        except Exception as e:
            print(f"[UltraIntelligentNameManager] ‚ùå Smart voice force check error: {e}")
            return "Error", "SMART_VOICE_FORCE_ERROR"

    def debug_smart_voice_status(self):
        """üêõ Debug smart voice recognition status"""
        if SMART_VOICE_AVAILABLE:
            smart_voice_recognition.debug_status()
        else:
            print("[UltraIntelligentNameManager] ‚ùå Smart voice recognition not available")

    def add_personal_name_alias(self, main_name: str, alias: str, user_id: str = None):
        """üî• Add personal name alias (user override)"""
        try:
            user_key = user_id or 'default'
            
            if user_key not in self.personal_name_overrides:
                self.personal_name_overrides[user_key] = {}
            
            if main_name not in self.personal_name_overrides[user_key]:
                self.personal_name_overrides[user_key][main_name] = []
            
            self.personal_name_overrides[user_key][main_name].append(alias.lower())
            self.user_whitelist_names.add(alias.lower())
            
            print(f"[UltraIntelligentNameManager] ‚úÖ Added alias: {main_name} ‚Üí {alias}")
            
            # Save to database
            self._save_personal_overrides()
            
        except Exception as e:
            print(f"[UltraIntelligentNameManager] ‚ùå Error adding alias: {e}")

    def handle_personal_override_command(self, text: str) -> Tuple[str, str]:
        """üî• Handle personal name override commands"""
        text_lower = text.lower().strip()
        
        # Pattern: "Remember, you can call me [alias]"
        override_patterns = [
            r'remember,?\s+you\s+can\s+call\s+me\s+(\w+)',
            r'you\s+can\s+also\s+call\s+me\s+(\w+)',
            r'call\s+me\s+(\w+)\s+for\s+short',
            r'my\s+nickname\s+is\s+(\w+)',
            r'i\s+also\s+go\s+by\s+(\w+)',
            r'add\s+(\w+)\s+as\s+my\s+alias',
            r'remember\s+(\w+)\s+as\s+my\s+name'
        ]
        
        for pattern in override_patterns:
            match = re.search(pattern, text_lower)
            if match:
                alias = match.group(1).title()
                
                # Get current user name (would need session context)
                current_user = 'Daveydrz'  # You'd get this from session
                self.add_personal_name_alias(current_user, alias)
                speak_streaming(f"Got it! I'll remember that you can be called {alias}.")
                return current_user, "ALIAS_ADDED"
        
        return "NoCommand", "NO_OVERRIDE_COMMAND"

    def _get_current_voice_cluster_id_enhanced(self) -> Optional[str]:
        """üîç Enhanced voice cluster ID detection with fallbacks"""
        try:
            # Method 1: Direct voice manager access
            if VOICE_MANAGER_AVAILABLE and voice_manager:
                if hasattr(voice_manager, 'current_speaker_cluster_id'):
                    cluster_id = voice_manager.current_speaker_cluster_id
                    if cluster_id:
                        print(f"[UltraIntelligentNameManager] üîç Voice manager cluster: {cluster_id}")
                        return cluster_id
                
                # Method 2: Get from active speaker
                if hasattr(voice_manager, 'get_current_speaker_cluster'):
                    cluster_id = voice_manager.get_current_speaker_cluster()
                    if cluster_id:
                        print(f"[UltraIntelligentNameManager] üîç Current speaker cluster: {cluster_id}")
                        return cluster_id
            
            # Method 3: Find most recent anonymous cluster
            if anonymous_clusters:
                # Sort by last_updated timestamp
                sorted_clusters = sorted(
                    anonymous_clusters.items(),
                    key=lambda x: x[1].get('last_updated', '2025-01-01T00:00:00'),
                    reverse=True
                )
                
                most_recent_cluster = sorted_clusters[0][0]
                print(f"[UltraIntelligentNameManager] üîç Most recent cluster: {most_recent_cluster}")
                return most_recent_cluster
            
            # Method 4: Check for active audio session
            try:
                from voice.audio_processor import audio_processor
                if hasattr(audio_processor, 'current_session_cluster'):
                    cluster_id = audio_processor.current_session_cluster
                    if cluster_id:
                        print(f"[UltraIntelligentNameManager] üîç Audio session cluster: {cluster_id}")
                        return cluster_id
            except ImportError:
                pass
            
            print(f"[UltraIntelligentNameManager] ‚ö†Ô∏è No voice cluster ID found via any method")
            return None
            
        except Exception as e:
            print(f"[UltraIntelligentNameManager] ‚ùå Error getting cluster ID: {e}")
            return None

    def _match_voice_with_relaxed_thresholds(self, name: str) -> bool:
        """üîä Match voice with relaxed similarity thresholds"""
        try:
            current_embedding = self._get_current_voice_embedding()
            if not current_embedding:
                print(f"[UltraIntelligentNameManager] ‚ö†Ô∏è No current voice embedding")
                return False
            
            # Check against anonymous clusters with relaxed thresholds
            if anonymous_clusters:
                for cluster_id, cluster_data in anonymous_clusters.items():
                    embeddings = cluster_data.get('embeddings', [])
                    if not embeddings:
                        continue
                    
                    # Compare with multiple similarity thresholds
                    thresholds = [0.85, 0.80, 0.75, 0.70]  # Progressively more lenient
                    
                    for threshold in thresholds:
                        for embedding in embeddings[-5:]:  # Check last 5 embeddings
                            try:
                                from voice.voice_models import dual_voice_model_manager
                                similarity = dual_voice_model_manager.compare_dual_embeddings(
                                    current_embedding, embedding
                                )
                                
                                if similarity >= threshold:
                                    print(f"[UltraIntelligentNameManager] üîä VOICE MATCH FOUND!")
                                    print(f"  Cluster: {cluster_id}")
                                    print(f"  Similarity: {similarity:.3f} (threshold: {threshold})")
                                    
                                    # Link this cluster to the name
                                    success = link_anonymous_to_named(cluster_id, name)
                                    if success:
                                        self.cluster_name_associations[cluster_id] = name
                                        print(f"[UltraIntelligentNameManager] ‚úÖ Successfully linked {cluster_id} ‚Üí {name}")
                                        return True
                                    
                            except Exception as e:
                                print(f"[UltraIntelligentNameManager] ‚ùå Embedding comparison error: {e}")
                                continue
            
            print(f"[UltraIntelligentNameManager] ‚ùå No voice match found for {name}")
            return False
            
        except Exception as e:
            print(f"[UltraIntelligentNameManager] ‚ùå Voice matching error: {e}")
            return False

    def _notify_voice_manager_about_name(self, name: str):
        """üîî Notify voice manager about name recognition"""
        try:
            if VOICE_MANAGER_AVAILABLE and voice_manager:
                if hasattr(voice_manager, 'update_current_speaker_name'):
                    voice_manager.update_current_speaker_name(name)
                    print(f"[UltraIntelligentNameManager] üîî Notified voice manager: {name}")
                else:
                    print(f"[UltraIntelligentNameManager] üîî Voice manager notification: {name}")
            else:
                print(f"[UltraIntelligentNameManager] üîî Name recognized: {name}")
        except Exception as e:
            print(f"[UltraIntelligentNameManager] ‚ùå Notification error: {e}")

    def _update_session_context_with_name(self, name: str):
        """üîÑ Update session context with recognized name"""
        try:
            # Update internal session context
            if not hasattr(self, 'session_context'):
                self.session_context = {}
            
            self.session_context['last_recognized_user'] = name
            self.session_context['recognition_timestamp'] = datetime.utcnow().isoformat()
            
            print(f"[UltraIntelligentNameManager] üîÑ Session context updated: {name}")
            
        except Exception as e:
            print(f"[UltraIntelligentNameManager] ‚ùå Error updating session context: {e}")

    def _boost_score_for_legitimate_names(self, text_lower: str, base_score: float) -> float:
        """üî• Boost score for legitimate name patterns"""
    
        # Extract potential name
        potential_name = self._extract_potential_name_from_text(text_lower)
    
        if potential_name and potential_name.lower() in ['david', 'daveydrz', 'francesco']:
            # Boost score for known legitimate names
            if re.search(r"\bi'?m\s+" + re.escape(potential_name.lower()), text_lower):
                boosted_score = base_score + 0.15  # Add 15% boost
                print(f"[UltraIntelligentNameManager] üî• LEGITIMATE NAME BOOST: {potential_name} ({base_score:.3f} ‚Üí {boosted_score:.3f})")
                return boosted_score
    
        return base_score

    def _get_current_voice_embedding(self):
        """üîç Get current voice embedding from voice manager"""
        try:
            from voice.manager import voice_manager
            
            if hasattr(voice_manager, 'get_current_voice_embedding'):
                return voice_manager.get_current_voice_embedding()
            
            return None
            
        except Exception as e:
            print(f"[UltraIntelligentNameManager] ‚ùå Error getting voice embedding: {e}")
            return None

    def _link_current_voice_to_name(self, name: str) -> bool:
        """üîó CRITICAL: Link current voice cluster to name"""
        try:
            # Get current voice cluster ID
            cluster_id = self._get_current_voice_cluster_id()
            if not cluster_id:
                print(f"[UltraIntelligentNameManager] ‚ùå No voice cluster ID found")
                return False
            
            # Get current voice embedding
            voice_embedding = self._get_current_voice_embedding()
            
            print(f"[UltraIntelligentNameManager] üîó Linking cluster {cluster_id} to name {name}")
            
            # Link anonymous cluster to named user
            success = link_anonymous_to_named(cluster_id, name)
            
            if success:
                # Update internal associations
                self.cluster_name_associations[cluster_id] = name
                
                # Record voice confidence
                if voice_embedding:
                    self.voice_confidence_tracker.record_voice_confidence(
                        name, voice_embedding, 0.95
                    )
                
                print(f"[UltraIntelligentNameManager] ‚úÖ Successfully linked {cluster_id} ‚Üí {name}")
                return True
            else:
                print(f"[UltraIntelligentNameManager] ‚ùå Failed to link {cluster_id} ‚Üí {name}")
                return False
                
        except Exception as e:
            print(f"[UltraIntelligentNameManager] ‚ùå Error linking voice to name: {e}")
            return False

    def _update_voice_clustering_after_name_recognition(self, name: str):
        """üîÑ Enhanced voice clustering update with multiple strategies"""
        try:
            print(f"[UltraIntelligentNameManager] üîÑ Starting voice clustering update for: {name}")
            
            # Strategy 1: Try relaxed voice matching first
            if self._match_voice_with_relaxed_thresholds(name):
                print(f"[UltraIntelligentNameManager] ‚úÖ Voice matched via relaxed thresholds")
                self._notify_voice_manager_about_name(name)
                self._update_session_context_with_name(name)
                return
            
            # Strategy 2: Try enhanced cluster ID detection
            cluster_id = self._get_current_voice_cluster_id_enhanced()
            if cluster_id:
                print(f"[UltraIntelligentNameManager] üîç Found cluster via enhanced detection: {cluster_id}")
                
                # Force link with current cluster
                success = link_anonymous_to_named(cluster_id, name)
                if success:
                    self.cluster_name_associations[cluster_id] = name
                    print(f"[UltraIntelligentNameManager] ‚úÖ Force-linked {cluster_id} ‚Üí {name}")
                    self._notify_voice_manager_about_name(name)
                    self._update_session_context_with_name(name)
                    return
            
            # Strategy 3: Create manual association if no cluster found
            print(f"[UltraIntelligentNameManager] ‚ö†Ô∏è No existing cluster found, creating manual association")
            
            # Get current voice embedding for future matching
            current_embedding = self._get_current_voice_embedding()
            if current_embedding:
                # Store embedding for future use
                manual_cluster_id = f"manual_{name}_{int(time.time())}"
                
                # Create a manual cluster entry
                if manual_cluster_id not in self.cluster_name_associations:
                    self.cluster_name_associations[manual_cluster_id] = name
                    
                    # Try to add to known_users directly
                    if name not in known_users:
                        known_users[name] = {
                            'status': 'trained',
                            'username': name,
                            'voice_embeddings': [current_embedding],
                            'created_at': datetime.utcnow().isoformat(),
                            'last_updated': datetime.utcnow().isoformat(),
                            'cluster_id': manual_cluster_id
                        }
                        save_known_users()
                        print(f"[UltraIntelligentNameManager] ‚úÖ Created manual profile for {name}")
            
            # Always notify regardless of linking success
            self._notify_voice_manager_about_name(name)
            self._update_session_context_with_name(name)
            
        except Exception as e:
            print(f"[UltraIntelligentNameManager] ‚ùå Voice clustering update error: {e}")

    def debug_voice_clustering_status_enhanced(self):
        """üêõ Enhanced debug with detailed voice clustering analysis"""
        print("\n" + "="*60)
        print("üêõ ENHANCED VOICE CLUSTERING DEBUG")
        print("="*60)
        
        # Known users analysis
        print(f"üìö Known Users ({len(known_users)}):")
        for username, data in known_users.items():
            if isinstance(data, dict):
                status = data.get('status', 'unknown')
                embeddings_count = len(data.get('voice_embeddings', []))
                cluster_id = data.get('cluster_id', 'none')
                print(f"  ‚Ä¢ {username}: {status}, {embeddings_count} embeddings, cluster: {cluster_id}")
        
        # Anonymous clusters analysis
        print(f"\nüîç Anonymous Clusters ({len(anonymous_clusters)}):")
        for cluster_id, cluster_data in anonymous_clusters.items():
            embeddings_count = len(cluster_data.get('embeddings', []))
            last_updated = cluster_data.get('last_updated', 'unknown')
            print(f"  ‚Ä¢ {cluster_id}: {embeddings_count} embeddings, updated: {last_updated}")
        
        # Current session info
        current_cluster = self._get_current_voice_cluster_id_enhanced()
        print(f"\nüé§ Current Session:")
        print(f"  ‚Ä¢ Cluster ID: {current_cluster}")
        print(f"  ‚Ä¢ Has embedding: {self._get_current_voice_embedding() is not None}")
        
        # Voice manager status
        print(f"\nüîä Voice Manager Status:")
        print(f"  ‚Ä¢ Available: {VOICE_MANAGER_AVAILABLE}")
        if VOICE_MANAGER_AVAILABLE and voice_manager:
            print(f"  ‚Ä¢ Has current_speaker_cluster_id: {hasattr(voice_manager, 'current_speaker_cluster_id')}")
            if hasattr(voice_manager, 'current_speaker_cluster_id'):
                print(f"  ‚Ä¢ Current speaker cluster: {getattr(voice_manager, 'current_speaker_cluster_id', 'None')}")
        
        # Associations
        print(f"\nüîó Cluster Associations ({len(self.cluster_name_associations)}):")
        for cluster_id, name in self.cluster_name_associations.items():
            print(f"  ‚Ä¢ {cluster_id} ‚Üí {name}")
        
        print("="*60 + "\n")
    def _update_session_context_with_name(self, name: str):
        """üîÑ Update session context with recognized name"""
        try:
            # Update internal session context
            if not hasattr(self, 'session_context'):
                self.session_context = {}
            
            self.session_context['last_recognized_user'] = name
            self.session_context['recognition_timestamp'] = datetime.utcnow().isoformat()
            
            print(f"[UltraIntelligentNameManager] üîÑ Session context updated: {name}")
            
        except Exception as e:
            print(f"[UltraIntelligentNameManager] ‚ùå Error updating session context: {e}")

    def check_voice_similarity_for_existing_users(self) -> Optional[str]:
        """üîç Check if current voice matches any existing user"""
        try:
            current_embedding = self._get_current_voice_embedding()
            if not current_embedding:
                return None
            
            # Check against all known users
            for username, profile_data in known_users.items():
                if isinstance(profile_data, dict) and 'voice_embeddings' in profile_data:
                    voice_embeddings = profile_data['voice_embeddings']
                    
                    if voice_embeddings:
                        # Compare with recent embeddings
                        recent_embeddings = voice_embeddings[-5:]  # Last 5 samples
                        
                        for stored_embedding in recent_embeddings:
                            try:
                                from voice.voice_models import dual_voice_model_manager
                                similarity = dual_voice_model_manager.compare_dual_embeddings(
                                    current_embedding, stored_embedding
                                )
                                
                                if similarity > 0.85:  # High similarity threshold
                                    print(f"[UltraIntelligentNameManager] üîç Voice match found: {username} (similarity: {similarity:.3f})")
                                    return username
                                    
                            except Exception as e:
                                print(f"[UltraIntelligentNameManager] ‚ùå Error comparing embeddings: {e}")
            
            return None
            
        except Exception as e:
            print(f"[UltraIntelligentNameManager] ‚ùå Error checking voice similarity: {e}")
            return None

    def debug_voice_clustering_status(self):
        """üêõ Debug voice clustering status"""
        print(f"[DEBUG] Known users: {list(known_users.keys())}")
        print(f"[DEBUG] Anonymous clusters: {list(anonymous_clusters.keys())}")
        print(f"[DEBUG] Cluster associations: {self.cluster_name_associations}")
        
        current_cluster = self._get_current_voice_cluster_id()
        print(f"[DEBUG] Current cluster: {current_cluster}")
        
        if current_cluster and current_cluster in self.cluster_name_associations:
            print(f"[DEBUG] Current cluster linked to: {self.cluster_name_associations[current_cluster]}")
        else:
            print(f"[DEBUG] Current cluster NOT linked to any name")

    def check_personal_whitelist(self, name: str) -> bool:
        """üî• Check if name is in personal whitelist"""
        name_lower = name.lower()
        
        # Check direct whitelist
        if name_lower in self.user_whitelist_names:
            print(f"[UltraIntelligentNameManager] ‚úÖ PERSONAL WHITELIST: {name}")
            return True
        
        # Check user aliases
        user_key = 'default'  # You'd get this from session
        if user_key in self.personal_name_overrides:
            for main_name, aliases in self.personal_name_overrides[user_key].items():
                if name_lower in aliases:
                    print(f"[UltraIntelligentNameManager] ‚úÖ PERSONAL ALIAS: {name} ‚Üí {main_name}")
                    return True
        
        return False

    def _save_personal_overrides(self):
        """üî• Save personal overrides to database"""
        try:
            # Save to database alongside known_users
            from voice.database import known_users, save_known_users
            
            # Add personal overrides to a special user entry
            override_key = "_personal_overrides"
            known_users[override_key] = {
                'type': 'personal_overrides',
                'data': self.personal_name_overrides,
                'whitelist': list(self.user_whitelist_names),
                'last_updated': datetime.utcnow().isoformat()
            }
            
            save_known_users()
            print(f"[UltraIntelligentNameManager] üíæ Personal overrides saved")
            
        except Exception as e:
            print(f"[UltraIntelligentNameManager] ‚ùå Error saving overrides: {e}")

    def handle_name_commands(self, text: str) -> Tuple[str, str]:
        """üî• ENHANCED: With voice similarity check first"""
        
        print(f"[UltraIntelligentNameManager] üî• ADVANCED Processing: '{text}'")
        
        # üîç FIRST: Check if voice matches existing user
        existing_user = self.check_voice_similarity_for_existing_users()
        if existing_user:
            print(f"[UltraIntelligentNameManager] üîç Voice recognized as existing user: {existing_user}")
            
            # Update session context
            self._update_session_context_with_name(existing_user)
            
            # Don't process as new introduction
            return existing_user, "VOICE_RECOGNIZED_EXISTING_USER"
        
        # Add to conversation memory
        self.contextual_conversation_memory.append({
            'text': text,
            'timestamp': datetime.utcnow().isoformat(),
            'context': self._analyze_conversation_context(text)
        })
        
        # Handle personal override commands first
        override_result = self.handle_personal_override_command(text)
        if override_result[1] != "NO_OVERRIDE_COMMAND":
            return override_result
        
        # Handle ongoing confirmations
        if self.pending_name_change_confirmation:
            return self.handle_name_change_confirmation(text)
        
        if self.waiting_for_new_name:
            return self.handle_new_name_response(text)
        
        # Handle explicit name change commands
        if self.is_name_change_command(text):
            return self.handle_name_change_request(text)
        
        # üî• ENHANCED: Multi-turn context analysis
        multi_turn_context = self.multi_turn_analyzer.analyze_multi_turn_context(
            text, self.contextual_conversation_memory
        )
        
        # Block if problematic multi-turn context
        if multi_turn_context.get('problematic_context', {}).get('detected'):
            print(f"[UltraIntelligentNameManager] üö® PROBLEMATIC MULTI-TURN CONTEXT")
            return "NoCommand", "PROBLEMATIC_CONTEXT_BLOCKED"
        
        # Extract name with enhanced processing
        if self.is_ultra_intelligent_spontaneous_introduction(text):
            extracted_name = self.extract_name_mega_intelligent(text)
            
            if extracted_name:
                # üî• ENHANCED: Check personal whitelist first
                if self.check_personal_whitelist(extracted_name):
                    print(f"[UltraIntelligentNameManager] ‚úÖ PERSONAL WHITELIST APPROVED: {extracted_name}")
                    return self.handle_ultra_intelligent_spontaneous_introduction(extracted_name, text)
                
                # üî• ENHANCED: Cultural variant auto-correction
                corrected_name = self._apply_cultural_variant_correction(extracted_name)
                if corrected_name != extracted_name:
                    print(f"[UltraIntelligentNameManager] üîÑ CULTURAL CORRECTION: {extracted_name} ‚Üí {corrected_name}")
                    extracted_name = corrected_name
                
                # üî• ENHANCED: Phoneme similarity check
                phoneme_match = self._check_phoneme_similarity(extracted_name)
                if phoneme_match:
                    print(f"[UltraIntelligentNameManager] üîä PHONEME MATCH: {extracted_name} ‚Üí {phoneme_match}")
                    extracted_name = phoneme_match
                
                # Continue with existing validation...
                if self.is_suspicious_name(extracted_name, text):
                    suspicious_reasons = self._get_suspicious_reasons(extracted_name, text)
                    
                    if self._is_extremely_suspicious(extracted_name, text, suspicious_reasons):
                        self._log_blocked_attempt(text, "extremely_suspicious", extracted_name)
                        return "NoCommand", "EXTREMELY_SUSPICIOUS_BLOCKED"
                    else:
                        speak_streaming(f"Did you say your name is {extracted_name}? Please say yes or no.")
                        self.pending_name_change_confirmation = True
                        self.new_name_suggestion = extracted_name
                        return extracted_name, "WAITING_CONFIRMATION"
                
                # ‚úÖ HIGH CONFIDENCE - PROCEED
                return self.handle_ultra_intelligent_spontaneous_introduction(extracted_name, text)
        
        return "NoCommand", "NO_COMMAND"

    def _apply_cultural_variant_correction(self, name: str) -> str:
        """üî• Apply cultural variant auto-correction"""
        name_lower = name.lower()
        
        # Check against cultural variants
        for main_name, variants in self.cultural_name_variants.items():
            if name_lower in variants:
                # Get current user context
                current_user = 'Daveydrz'  # You'd get this from session
                if current_user and current_user.lower() == main_name:
                    print(f"[UltraIntelligentNameManager] üåç CULTURAL VARIANT: {name} ‚Üí {main_name.title()}")
                    return main_name.title()
        
        return name

    def _check_phoneme_similarity(self, name: str) -> Optional[str]:
        """üî• Check phoneme similarity against known users"""
        current_user = 'Daveydrz'  # You'd get this from session
        
        if current_user:
            # Check if this is a phoneme variant of current user
            if self.phoneme_analyzer.is_phoneme_variant(name, current_user):
                return current_user
        
        # Check against all known users
        for known_name in self.enhanced_name_database:
            if self.phoneme_analyzer.is_phoneme_variant(name, known_name):
                return known_name.title()
        
        return None

    def _is_extremely_suspicious(self, name: str, text: str, suspicious_reasons: List[str]) -> bool:
        """üõ°Ô∏è BULLETPROOF: Extremely suspicious name detection"""
        
        # üö® EXTREMELY SUSPICIOUS CONDITIONS
        extremely_suspicious_conditions = [
            len(suspicious_reasons) >= 3,  # Multiple red flags
            "buddy_confusion" in suspicious_reasons,
            "possessive_relation_trap" in suspicious_reasons,
            "fake_name_trap" in suspicious_reasons and "unknown_name" in suspicious_reasons,
            len(name) < 3 and "unknown_name" in suspicious_reasons
        ]
        
        is_extremely_suspicious = any(extremely_suspicious_conditions)
        
        if is_extremely_suspicious:
            print(f"[UltraIntelligentNameManager] üö® EXTREMELY SUSPICIOUS: {name}")
            print(f"[UltraIntelligentNameManager] üö® Reasons: {suspicious_reasons}")
        
        return is_extremely_suspicious

    def _log_blocked_attempt(self, text: str, reason: str, name: str = None):
        """üìä LOG BLOCKED ATTEMPT"""
        blocked_entry = {
            'text': text,
            'blocked_name': name,
            'block_reason': reason,
            'timestamp': datetime.utcnow().isoformat()
        }
        
        self.false_positive_learning.append(blocked_entry)
        print(f"[UltraIntelligentNameManager] üìä BLOCKED ATTEMPT LOGGED: {reason}")

    
    def is_fake_name_trap(self, name: str) -> bool:
        """üõ°Ô∏è ULTRA-COMPREHENSIVE fake name trap detection"""
        if not name:
            return True
        
        name_lower = name.lower().strip()
        is_trap = name_lower in FAKE_NAME_TRAPS
        
        if is_trap:
            print(f"[UltraIntelligentNameManager] üõ°Ô∏è FAKE NAME TRAP: {name}")
        
        return is_trap
    
    def is_possessive_or_relation_trap(self, name: str, text: str) -> bool:
        """üõ°Ô∏è ULTRA-INTELLIGENT possessive/relationship trap detection"""
        if not name:
            return True
        
        name_lower = name.lower().strip()
        text_lower = text.lower().strip()
        
        # Check for possessive forms
        if name_lower.endswith("'s") or name_lower.endswith("'s"):
            print(f"[UltraIntelligentNameManager] üõ°Ô∏è POSSESSIVE TRAP: {name}")
            return True
        
        # Enhanced relationship keyword detection
        relation_keywords = {
            "friend", "brother", "sister", "mum", "dad", "mother", "father", 
            "son", "daughter", "husband", "wife", "boyfriend", "girlfriend",
            "cousin", "uncle", "aunt", "nephew", "niece", "grandpa", "grandma",
            "colleague", "coworker", "boss", "employee", "neighbor", "roommate",
            "classmate", "teammate", "partner", "buddy", "pal", "mate"
        }
        
        # Tokenize and analyze context
        words = text_lower.split()
        for i, word in enumerate(words):
            # Look for "I'm [name] [relationship]" pattern
            if word in {"i'm", "im", "i'm"} and i + 2 < len(words):
                potential_name = words[i + 1].strip(".,!?")
                relation_word = words[i + 2].strip(".,!?")
                
                if potential_name == name_lower and relation_word in relation_keywords:
                    print(f"[UltraIntelligentNameManager] üõ°Ô∏è RELATION TRAP: I'm {name} {relation_word}")
                    return True
        
        # Check for "David's friend" patterns
        possessive_patterns = [
            rf"\b{re.escape(name_lower)}'s\s+\w+",
            rf"\b{re.escape(name_lower)}'s\s+\w+",
            rf"\bof\s+{re.escape(name_lower)}\b",
            rf"\bwith\s+{re.escape(name_lower)}\b"
        ]
        
        for pattern in possessive_patterns:
            if re.search(pattern, text_lower):
                print(f"[UltraIntelligentNameManager] üõ°Ô∏è POSSESSIVE PATTERN: {pattern}")
                return True
        
        return False
    
    def is_suspicious_name(self, name: str, text: str) -> bool:
        """üîç ULTRA-COMPREHENSIVE suspicious name detection"""
        if not name:
            return True
        
        name_lower = name.lower().strip()
        text_lower = text.lower().strip()
        suspicious = False
        reasons = []
        
        # Check fake name traps
        if self.is_fake_name_trap(name):
            suspicious = True
            reasons.append("fake_name_trap")
        
        # Check possessive/relationship traps
        if self.is_possessive_or_relation_trap(name, text):
            suspicious = True
            reasons.append("possessive_relation_trap")
        
        # Check for "buddy" confusion (critical for your case)
        if "buddy" in text_lower and name_lower.startswith("b"):
            suspicious = True
            reasons.append("buddy_confusion")
        
        # Check if unknown name (not in database)
        if name_lower not in self.enhanced_name_database:
            suspicious = True
            reasons.append("unknown_name")
        
        # Check name length
        if len(name_lower) < 3:
            suspicious = True
            reasons.append("short_name")
        
        # Check for emotional state context
        emotional_context_patterns = [
            rf"\bi\'?m\s+{re.escape(name_lower)}\s+(fine|good|okay|well|bad|tired|busy|ready)",
            rf"\bi\'?m\s+{re.escape(name_lower)}\s+(and|but|so|then|now)",
            rf"\bi\'?m\s+{re.escape(name_lower)}\s+(to|for|with|at|in|on)"
        ]
        
        for pattern in emotional_context_patterns:
            if re.search(pattern, text_lower):
                suspicious = True
                reasons.append("emotional_context")
                break
        
        if suspicious:
            print(f"[UltraIntelligentNameManager] üîç SUSPICIOUS NAME: {name} - Reasons: {reasons}")
        
        return suspicious

    def _load_ultra_comprehensive_names(self) -> Set[str]:
        """üåç Load ultra-comprehensive international name database"""
        
        # Core user names
        core_names = {'daveydrz', 'davey', 'dave', 'david', 'dawid', 'davy', 'francesco'}
        
        # Ultra-comprehensive international database (keeping your massive list)
        global_names = {
            # English/American names (comprehensive)
            'aaron', 'adam', 'adrian', 'alan', 'albert', 'alex', 'alexander', 'andrew', 'anthony', 'arthur',
            'austin', 'benjamin', 'bernard', 'bradley', 'brandon', 'brian', 'bruce', 'bryan', 'carl', 'carlos',
            'charles', 'christian', 'christopher', 'daniel', 'david', 'dennis', 'douglas', 'edward', 'eric',
            'eugene', 'frank', 'gary', 'george', 'gerald', 'gregory', 'harold', 'henry', 'jacob', 'james',
            'jason', 'jeffrey', 'jeremy', 'jesse', 'john', 'jonathan', 'joseph', 'joshua', 'justin', 'keith',
            'kenneth', 'kevin', 'kyle', 'larry', 'lawrence', 'louis', 'mark', 'matthew', 'michael', 'nicholas',
            'patrick', 'paul', 'peter', 'phillip', 'raymond', 'richard', 'robert', 'roger', 'ronald', 'ryan',
            'samuel', 'scott', 'sean', 'stephen', 'steven', 'thomas', 'timothy', 'tyler', 'walter', 'william',
            
            # Female names (comprehensive)
            'abigail', 'alice', 'amanda', 'amy', 'andrea', 'angela', 'anna', 'ashley', 'barbara', 'betty',
            'brenda', 'carol', 'carolyn', 'catherine', 'cheryl', 'christine', 'cynthia', 'deborah', 'debra',
            'denise', 'diane', 'donna', 'dorothy', 'elizabeth', 'emily', 'emma', 'evelyn', 'frances', 'gloria',
            'helen', 'jacqueline', 'janet', 'janice', 'jean', 'jennifer', 'jessica', 'joan', 'joyce', 'judith',
            'judy', 'julia', 'julie', 'karen', 'katherine', 'kathleen', 'kathryn', 'kelly', 'kimberly', 'laura',
            'linda', 'lisa', 'lori', 'louise', 'margaret', 'maria', 'marie', 'marilyn', 'martha', 'mary',
            'megan', 'melissa', 'michelle', 'nancy', 'nicole', 'olivia', 'pamela', 'patricia', 'rachel',
            'rebecca', 'rose', 'ruth', 'sandra', 'sarah', 'sharon', 'shirley', 'stephanie', 'susan', 'teresa',
            'theresa', 'virginia', 'wanda',
            
            # Italian names (comprehensive)
            'alessandro', 'andrea', 'antonio', 'carlo', 'claudio', 'davide', 'diego', 'enrico', 'fabio',
            'francesco', 'franco', 'gabriele', 'giacomo', 'giovanni', 'giulio', 'giuseppe', 'lorenzo',
            'luca', 'luciano', 'luigi', 'manuel', 'marco', 'mario', 'massimo', 'matteo', 'maurizio',
            'michele', 'nicola', 'paolo', 'pietro', 'riccardo', 'roberto', 'salvatore', 'sergio', 'stefano',
            'vincenzo', 'vittorio', 'alessandra', 'angela', 'anna', 'antonella', 'barbara', 'carla',
            'carmen', 'chiara', 'claudia', 'cristina', 'daniela', 'elena', 'elisabetta', 'federica',
            'francesca', 'giovanna', 'giulia', 'giuseppina', 'laura', 'lucia', 'luisa', 'manuela',
            'margherita', 'maria', 'marina', 'marta', 'monica', 'paola', 'patrizia', 'roberta',
            'rosa', 'rossella', 'sara', 'serena', 'silvia', 'simona', 'stefania', 'valentina', 'valeria',
            
            # Spanish names (comprehensive)
            'alejandro', 'antonio', 'carlos', 'daniel', 'david', 'diego', 'eduardo', 'enrique', 'fernando',
            'francisco', 'javier', 'jesus', 'joaquin', 'jorge', 'jose', 'juan', 'luis', 'manuel', 'miguel',
            'pablo', 'pedro', 'rafael', 'ramon', 'raul', 'ricardo', 'roberto', 'salvador', 'sergio',
            'vicente', 'adrian', 'alejandra', 'ana', 'andrea', 'angela', 'carmen', 'cristina', 'elena',
            'eva', 'francisca', 'isabel', 'laura', 'lucia', 'maria', 'marta', 'monica', 'patricia',
            'pilar', 'rosa', 'sandra', 'silvia', 'teresa', 'veronica',
            
            # German names (comprehensive)
            'alexander', 'andreas', 'bernd', 'christian', 'christoph', 'daniel', 'dieter', 'frank',
            'hans', 'heinz', 'helmut', 'jens', 'joachim', 'jorg', 'jurgen', 'karl', 'klaus', 'manfred',
            'markus', 'martin', 'matthias', 'michael', 'norbert', 'peter', 'rainer', 'stefan', 'thomas',
            'torsten', 'uwe', 'werner', 'wolfgang', 'andrea', 'angelika', 'anna', 'antje', 'barbara',
            'beate', 'birgit', 'brigitte', 'christina', 'christine', 'claudia', 'doris', 'elisabeth',
            'gabriele', 'gisela', 'heike', 'helga', 'ingrid', 'karin', 'katrin', 'kerstin', 'kirsten',
            'marion', 'martina', 'monika', 'petra', 'renate', 'sabine', 'silke', 'stefanie', 'susanne',
            'ute', 'ursula',
            
            # French names (comprehensive)
            'alain', 'andre', 'antoine', 'bernard', 'bruno', 'christian', 'christophe', 'claude',
            'daniel', 'david', 'didier', 'dominique', 'eric', 'fabrice', 'francois', 'frederic',
            'gerard', 'guillaume', 'henri', 'herve', 'jacques', 'jean', 'jerome', 'julien', 'laurent',
            'marc', 'marcel', 'michel', 'nicolas', 'olivier', 'pascal', 'patrick', 'paul', 'philippe',
            'pierre', 'rene', 'robert', 'serge', 'stephane', 'sylvain', 'thierry', 'vincent', 'yves',
            'agnes', 'anne', 'annie', 'brigitte', 'catherine', 'cecile', 'chantal', 'christine',
            'claire', 'corinne', 'danielle', 'dominique', 'elizabeth', 'florence', 'francoise',
            'genevieve', 'helene', 'isabelle', 'jacqueline', 'jeanne', 'karine', 'laurence', 'marie',
            'martine', 'michele', 'monique', 'nadine', 'nathalie', 'nicole', 'pascale', 'patricia',
            'sandrine', 'sophie', 'sylvie', 'valerie', 'veronique', 'virginie',
            
            # Modern/Popular names (comprehensive)
            'aiden', 'alex', 'avery', 'blake', 'cameron', 'casey', 'dakota', 'drew', 'emerson',
            'finley', 'harper', 'hayden', 'hunter', 'jamie', 'jordan', 'kai', 'kendall', 'logan',
            'mason', 'morgan', 'noah', 'parker', 'peyton', 'quinn', 'reese', 'riley', 'rowan',
            'sage', 'skylar', 'taylor', 'tatum', 'emery', 'river', 'phoenix', 'raven',
            'storm', 'winter', 'autumn', 'summer', 'rain', 'sky', 'ocean', 'forest', 'dawn',
            
            # Short/Nickname variations
            'al', 'ed', 'jo', 'bo', 'ty', 'max', 'ben', 'dan', 'tom', 'jim', 'tim', 'kim',
            'pat', 'sue', 'jan', 'ann', 'eve', 'ivy', 'ray', 'roy', 'guy', 'leo', 'eli',
            'abe', 'vic', 'art', 'ron', 'jon', 'don', 'bob', 'rob', 'rick', 'nick', 'mick',
            'jack', 'zack', 'luke', 'mark', 'paul', 'pete', 'phil', 'bill', 'will', 'carl',
            'earl', 'fred', 'gene', 'glen', 'hugh', 'ivan', 'joel', 'kent', 'lane', 'neil',
            'otto', 'ross', 'seth', 'wade', 'zane'
        }
        
        return core_names.union(global_names)
    
    def _load_cultural_variants(self) -> Dict[str, List[str]]:
        """üåç Load cultural name variants for ultra-intelligent matching"""
        return {
            'david': ['dave', 'davey', 'davy', 'davie', 'daveed', 'dawid', 'davide', 'daved'],
            'daveydrz': ['davey', 'dave', 'davy', 'davie', 'david', 'dawid'],
            'francesco': ['franco', 'frank', 'francis', 'francois', 'franz', 'cisco', 'paco'],
            'michael': ['mike', 'mick', 'mickey', 'mikey', 'mikhail', 'michel', 'miguel'],
            'robert': ['rob', 'bob', 'robbie', 'bobby', 'bert', 'roberto', 'rupert'],
            'william': ['will', 'bill', 'billy', 'willie', 'liam', 'guillaume', 'wilhelm'],
            'elizabeth': ['liz', 'beth', 'betty', 'eliza', 'lisa', 'libby', 'elsie'],
            'jennifer': ['jen', 'jenny', 'jenni', 'jenna', 'ginny'],
            'christopher': ['chris', 'christie', 'kristopher', 'christophe'],
            'alexander': ['alex', 'xander', 'alessandro', 'alexandro', 'alejandro'],
            'anthony': ['tony', 'antoine', 'antonio', 'anton'],
            'patricia': ['pat', 'patty', 'trish', 'tricia', 'patrizia'],
            'charles': ['charlie', 'chuck', 'carlos', 'carlo', 'karl'],
            'margaret': ['maggie', 'meg', 'peggy', 'margot', 'margie'],
            'joseph': ['joe', 'joey', 'jose', 'giuseppe', 'josef'],
            'richard': ['rick', 'rich', 'dick', 'ricardo', 'riccardo'],
            'thomas': ['tom', 'tommy', 'thom', 'tomas', 'tommaso'],
            'matthew': ['matt', 'matty', 'matteo', 'matias', 'mathieu'],
            'daniel': ['dan', 'danny', 'daniele', 'dani'],
            'james': ['jim', 'jimmy', 'jamie', 'jaime', 'giacomo'],
            'john': ['jon', 'johnny', 'jack', 'giovanni', 'juan', 'jean']
        }
    
    def _build_phonetic_similarity_map(self) -> Dict[str, Set[str]]:
        """üî§ Build phonetic similarity mapping for ultra-intelligent matching"""
        phonetic_groups = {
            'b_p_sounds': {'bobby', 'poppy', 'baby', 'puppy', 'happy', 'peppy'},
            'k_g_sounds': {'kelly', 'gary', 'kenny', 'golly', 'carry', 'gerry'},
            'd_t_sounds': {'david', 'tavid', 'daddy', 'teddy', 'ready', 'steady'},
            'f_v_sounds': {'frank', 'vrank', 'funny', 'very', 'coffee', 'heavy'},
            'l_r_sounds': {'larry', 'rerry', 'really', 'lilly', 'rally', 'holly'},
            'm_n_sounds': {'mary', 'nary', 'mommy', 'nanny', 'many', 'money'},
            's_z_sounds': {'sarah', 'zarah', 'busy', 'fuzzy', 'easy', 'cozy'},
            'sh_ch_sounds': {'charlie', 'sharlie', 'checking', 'sharing', 'catching', 'washing'},
            'th_f_sounds': {'thomas', 'fomas', 'thinking', 'finking', 'therapy', 'ferry'},
            'w_v_sounds': {'walter', 'valter', 'working', 'very', 'water', 'vector'}
        }
        
        similarity_map = defaultdict(set)
        for group_name, words in phonetic_groups.items():
            for word in words:
                similarity_map[word].update(words - {word})
        
        return dict(similarity_map)
    
    def _load_temporal_patterns(self) -> Dict[str, List[str]]:
        """‚è∞ Load temporal name patterns for context-aware processing"""
        return {
            'morning_casual': ['morning', 'early', 'wake', 'breakfast', 'coffee', 'start'],
            'afternoon_professional': ['afternoon', 'work', 'meeting', 'business', 'office', 'lunch'],
            'evening_relaxed': ['evening', 'dinner', 'relax', 'home', 'family', 'rest'],
            'night_informal': ['night', 'late', 'tired', 'sleep', 'bed', 'quiet'],
            'weekend_casual': ['weekend', 'saturday', 'sunday', 'casual', 'fun', 'free'],
            'weekday_formal': ['monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'work', 'busy']
        }
    
    def _load_whisper_error_patterns(self) -> Dict[str, List[str]]:
        """üé§ Load comprehensive Whisper ASR error patterns"""
        return {
            'common_mistranscriptions': [
                'bobby', 'robbie', 'tommy', 'jimmy', 'johnny', 'billy', 'willy', 'kenny',
                'danny', 'ricky', 'mickey', 'joey', 'tony', 'ronnie', 'donnie', 'stevie',
                'ready', 'busy', 'sorry', 'happy', 'lucky', 'funny', 'silly', 'pretty',
                'dirty', 'empty', 'heavy', 'angry', 'hungry', 'thirsty', 'sleepy', 'tired',
                'bored', 'scared', 'worried', 'excited', 'confused', 'working', 'talking',
                'walking', 'running', 'eating', 'drinking', 'sleeping', 'thinking', 'trying',
                'going', 'coming', 'leaving', 'staying', 'waiting', 'listening', 'watching',
                'reading', 'writing', 'playing', 'singing', 'dancing', 'cooking', 'cleaning',
                'shopping', 'driving', 'flying', 'swimming', 'learning', 'teaching', 'helping'
            ],
            'phonetic_errors': {
                'b_p_confusion': ['bobby', 'poppy', 'baby', 'puppy'],
                'k_g_confusion': ['kelly', 'gary', 'kenny', 'golly'],
                # üîß FIX: Remove 'david' from d_t_confusion
                'd_t_confusion': ['tavid', 'daddy', 'teddy'],  # Removed 'david'
                'f_v_confusion': ['frank', 'vrank', 'funny', 'very'],
                'l_r_confusion': ['larry', 'rerry', 'really', 'lilly'],
                'm_n_confusion': ['mary', 'nary', 'mommy', 'nanny'],
                's_z_confusion': ['sarah', 'zarah', 'busy', 'fuzzy'],
                'sh_ch_confusion': ['charlie', 'sharlie', 'checking', 'sharing'],
                'th_f_confusion': ['thomas', 'fomas', 'thinking', 'finking'],
                'w_v_confusion': ['walter', 'valter', 'working', 'very']
            },
            'ambient_noise_errors': [
                'noisy', 'cloudy', 'windy', 'rainy', 'stormy', 'snowy', 'foggy', 'dusty',
                'muddy', 'sandy', 'rocky', 'woody', 'grassy', 'leafy', 'flowery', 'sunny'
            ],
            'emotional_state_errors': [
                'happy', 'sad', 'mad', 'glad', 'bad', 'good', 'great', 'fine', 'okay',
                'well', 'sick', 'hurt', 'pain', 'sore', 'weak', 'strong', 'tough', 'soft'
            ],
            'action_state_errors': [
                'doing', 'going', 'coming', 'running', 'walking', 'talking', 'working',
                'playing', 'eating', 'drinking', 'sleeping', 'reading', 'writing', 'listening'
            ]
        }

    def is_ultra_intelligent_spontaneous_introduction(self, text: str) -> bool:
        """üß† ULTRA-INTELLIGENT spontaneous introduction detection"""
        
        print(f"[UltraIntelligentNameManager] üß† ULTRA-AI introduction analysis: '{text}'")
        
        text_lower = text.lower().strip()
        
        # ‚úÖ PHASE 1: IMMEDIATE ULTRA-INTELLIGENT REJECTIONS
        if self._is_ultra_intelligent_command_detection(text_lower):
            print(f"[UltraIntelligentNameManager] üß† ULTRA-AI COMMAND REJECTED")
            return False
        
        if self._is_whisper_error_pattern(text_lower):
            print(f"[UltraIntelligentNameManager] üß† WHISPER ERROR PATTERN REJECTED")
            return False
        
        if self._is_casual_conversation_pattern(text_lower):
            print(f"[UltraIntelligentNameManager] üß† CASUAL CONVERSATION REJECTED")
            return False
        
        # ‚úÖ PHASE 2: CONVERSATION CONTEXT ANALYSIS
        conversation_context = self.conversation_context_analyzer.analyze_context(text)
        if conversation_context['conversation_type'] == 'command_sequence':
            print(f"[UltraIntelligentNameManager] üß† COMMAND SEQUENCE CONTEXT REJECTED")
            return False
        
        # ‚úÖ PHASE 3: ULTRA-INTELLIGENT PATTERN ANALYSIS
        linguistic_analysis = self.linguistic_validator.analyze_introduction_patterns(text_lower)
        if linguistic_analysis['confidence'] < 0.3:  # üîß FIX: Lowered from 0.6
            print(f"[UltraIntelligentNameManager] üß† LINGUISTIC ANALYSIS REJECTED: {linguistic_analysis['confidence']:.3f}")
            return False
        
        # ‚úÖ PHASE 4: MULTI-FACTOR INTRODUCTION VALIDATION
        introduction_score = self._calculate_ultra_intelligent_introduction_score(text_lower)
        
        print(f"[UltraIntelligentNameManager] üß† ULTRA-AI INTRODUCTION SCORE: {introduction_score:.3f}")
        
        # üîß FIX: Lowered threshold from 0.85 to 0.65
        return introduction_score > 0.50
    
    def _is_ultra_intelligent_command_detection(self, text_lower: str) -> bool:
        """üß† ULTRA-INTELLIGENT command detection beyond GPT-4 level"""
        
        # üîß NEW: Allow introduction "call me" patterns FIRST
        introduction_call_patterns = [
            r'\bcall\s+me\s+\w+',
            r'\bpeople\s+call\s+me\s+\w+', 
            r'\bfriends\s+call\s+me\s+\w+',
            r'\beveryone\s+calls\s+me\s+\w+',
            r'\bthey\s+call\s+me\s+\w+',
            r'\bmy\s+friends\s+call\s+me\s+\w+',
            r'\byou\s+can\s+call\s+me\s+\w+',
        ]
        
        # If it matches introduction pattern, don't block as command
        if any(re.search(pattern, text_lower) for pattern in introduction_call_patterns):
            print(f"[UltraIntelligentNameManager] ‚úÖ INTRODUCTION CALL PATTERN ALLOWED")
            return False  # Don't block as command
        
        # ‚úÖ STRATEGY 1: ADVANCED SEMANTIC COMMAND ANALYSIS
        semantic_command_indicators = [
            # Direct imperatives with ultra-intelligent context (more specific)
            r"^(please\s+)?(can\s+you\s+|could\s+you\s+|would\s+you\s+|will\s+you\s+)?call\s+(mom|dad|home|work|doctor|police|911|emergency|him|her|them)",
            r"^(please\s+)?(can\s+you\s+|could\s+you\s+|would\s+you\s+|will\s+you\s+)?(phone|text|message|contact|reach|dial|ring)",
            r"^(please\s+)?(can\s+you\s+|could\s+you\s+|would\s+you\s+|will\s+you\s+)?(tell|ask|show|give|send|email|forward|share)",
            r"^(please\s+)?(can\s+you\s+|could\s+you\s+|would\s+you\s+|will\s+you\s+)?(find|search|look|locate|get|fetch|retrieve|discover)",
            r"^(please\s+)?(can\s+you\s+|could\s+you\s+|would\s+you\s+|will\s+you\s+)?(play|start|stop|pause|resume|open|close|launch)",
            r"^(please\s+)?(can\s+you\s+|could\s+you\s+|would\s+you\s+|will\s+you\s+)?(turn|switch|toggle|enable|disable|activate|deactivate)",
            r"^(please\s+)?(can\s+you\s+|could\s+you\s+|would\s+you\s+|will\s+you\s+)?(set|create|make|build|generate|schedule|book|cancel)",
            r"^(please\s+)?(can\s+you\s+|could\s+you\s+|would\s+you\s+|will\s+you\s+)?(remind|alert|notify|warn|update|sync|backup|save)",
            r"^(please\s+)?(can\s+you\s+|could\s+you\s+|would\s+you\s+|will\s+you\s+)?(help|assist|support|guide|teach|explain|translate)",
            
            # Assistant activation patterns
            r"^(hey\s+|ok\s+|okay\s+)?(buddy|alexa|siri|google|cortana|assistant)",
            r"^(excuse\s+me|pardon\s+me|sorry\s+to\s+bother|listen\s+up)",
            
            # Question command structures
            r"^(what\s+is|what's|where\s+is|where's|when\s+is|when's|how\s+do|how\s+can|how\s+to)",
            r"^(do\s+you\s+know|can\s+you\s+tell\s+me|could\s+you\s+tell\s+me|would\s+you\s+know)",
            r"^(is\s+there|are\s+there|do\s+we\s+have|can\s+we\s+get|should\s+we|would\s+it\s+be)"
        ]
        
        for pattern in semantic_command_indicators:
            if re.search(pattern, text_lower):
                print(f"[UltraIntelligentNameManager] üß† ULTRA-AI COMMAND PATTERN: {pattern}")
                return True
        
        return False
    
    def _is_casual_conversation_pattern(self, text_lower: str) -> bool:
        """üí¨ ULTRA-INTELLIGENT casual conversation detection"""
        
        # Ultra-comprehensive casual conversation patterns
        casual_patterns = [
            r"^i'?m\s+(\w+)\s+(fine|good|great|okay|well|better|worse|terrible|awful|amazing|fantastic|excellent|bad|horrible|sick|tired|exhausted|energetic|excited|happy|sad|angry|frustrated|confused|lost|found|busy|free|available|unavailable|ready|not\s+ready|here|there|home|work|school|outside|inside|upstairs|downstairs|online|offline|late|early)",
            r"^i'?m\s+(\w+)\s+(doing|going|coming|working|talking|walking|running|eating|drinking|sleeping|thinking|trying|playing|singing|dancing|cooking|cleaning|shopping|driving|flying|swimming|learning|teaching|helping|studying|reading|writing|listening|watching)"
        ]
        
        for pattern in casual_patterns:
            if re.search(pattern, text_lower):
                print(f"[UltraIntelligentNameManager] üí¨ CASUAL PATTERN: {pattern}")
                return True
        
        return False

    def _is_whisper_error_pattern(self, text_lower: str) -> bool:
        """üé§ ULTRA-INTELLIGENT Whisper ASR error detection"""
        
        # Extract potential name from simple patterns
        simple_patterns = [r"^i'?m\s+(\w+)$", r"^i\s+am\s+(\w+)$", r"^this\s+is\s+(\w+)$"]
        potential_name = None
        
        for pattern in simple_patterns:
            match = re.search(pattern, text_lower)
            if match:
                potential_name = match.group(1).lower()
                break
        
        if not potential_name:
            return False
        
        # üîß FIX: Don't flag legitimate names as errors
        legitimate_names = {'david', 'daveydrz', 'davey', 'dave', 'francesco', 'frank', 'franco'}
        if potential_name in legitimate_names:
            print(f"[UltraIntelligentNameManager] ‚úÖ LEGITIMATE NAME EXEMPTION: {potential_name}")
            return False
        
        # Check against comprehensive Whisper error patterns
        for category, errors in self.whisper_error_patterns.items():
            if category == 'common_mistranscriptions':
                if potential_name in errors:
                    print(f"[UltraIntelligentNameManager] üé§ WHISPER ERROR: {potential_name} in {category}")
                    return True
            elif category == 'phonetic_errors':
                for error_type, error_list in errors.items():
                    if potential_name in error_list:
                        # üîß FIX: Only flag if NOT a legitimate name
                        if potential_name not in legitimate_names:
                            print(f"[UltraIntelligentNameManager] üé§ PHONETIC ERROR: {potential_name} in {error_type}")
                            return True
            elif isinstance(errors, list) and potential_name in errors:
                print(f"[UltraIntelligentNameManager] üé§ WHISPER ERROR: {potential_name} in {category}")
                return True
        
        return False

    
    def _calculate_ultra_intelligent_introduction_score(self, text_lower: str) -> float:
        """üß† ULTRA-INTELLIGENT introduction confidence scoring"""
        
        # Extract features for confidence prediction
        features = {
            'explicit_introduction': self._has_explicit_introduction_phrase(text_lower),
            'greeting_context': self._has_greeting_context(text_lower),
            'name_database_match': self._has_name_database_match(text_lower),
            'cultural_variant': self._has_cultural_variant(text_lower),
            'sentence_structure': self._has_good_sentence_structure(text_lower),
            'whisper_error_penalty': self._is_whisper_error_pattern(text_lower),
            'casual_conversation_penalty': self._is_casual_conversation_pattern(text_lower),
            'command_context_penalty': self._is_ultra_intelligent_command_detection(text_lower),
            'unknown_name_penalty': self._has_unknown_name(text_lower)
        }
        
        # Use the confidence predictor
        confidence = self.confidence_predictor.predict_confidence(features)
        confidence = self._boost_score_for_legitimate_names(text_lower, confidence)
        
        print(f"[UltraIntelligentNameManager] üß† ULTRA-AI CONFIDENCE FEATURES: {features}")
        print(f"[UltraIntelligentNameManager] üß† PREDICTED CONFIDENCE: {confidence:.3f}")
        
        return confidence

    # Helper methods for feature extraction
    def _has_explicit_introduction_phrase(self, text_lower):
        explicit_phrases = ['my name is', 'call me', 'i am called', 'you can call me', "i'm", "im"]
        return any(phrase in text_lower for phrase in explicit_phrases)
    
    def _has_greeting_context(self, text_lower):
        greetings = ['hello', 'hi', 'hey', 'nice to meet']
        return any(greeting in text_lower for greeting in greetings)
    
    def _has_name_database_match(self, text_lower):
        potential_name = self._extract_potential_name_from_text(text_lower)
        return potential_name and potential_name.lower() in self.enhanced_name_database
    
    def _has_cultural_variant(self, text_lower):
        potential_name = self._extract_potential_name_from_text(text_lower)
        if not potential_name:
            return False
        
        for main_name, variants in self.cultural_name_variants.items():
            if potential_name.lower() in variants or potential_name.lower() == main_name:
                return True
        return False
    
    def _has_good_sentence_structure(self, text_lower):
        return self._is_declarative_introduction_structure(text_lower)
    
    def _has_unknown_name(self, text_lower):
        potential_name = self._extract_potential_name_from_text(text_lower)
        if not potential_name:
            return False
        
        return potential_name.lower() not in self.enhanced_name_database
    
    def _extract_potential_name_from_text(self, text_lower: str) -> Optional[str]:
        """üîç Extract potential name for validation"""
        
        patterns = [
            r"my name is (\w+)",
            r"call me (\w+)",
            r"i am called (\w+)",
            r"you can call me (\w+)",
            r"people call me (\w+)",
            r"i go by (\w+)",
            r"the name is (\w+)",
            r"i am known as (\w+)",
            r"everyone calls me (\w+)",
            r"^hello,? (?:i'?m |my name is |call me |this is )(\w+)",
            r"^hi,? (?:i'?m |my name is |call me |this is )(\w+)",
            r"^hey,? (?:i'?m |my name is |call me |this is )(\w+)",
            r"^this is (\w+)$",
            r"^i'?m (\w+)$",
            r"^i am (\w+)$"
        ]
        
        for pattern in patterns:
            match = re.search(pattern, text_lower)
            if match:
                return match.group(1).title()
        
        return None
    
    def _is_declarative_introduction_structure(self, text_lower: str) -> bool:
        """üìù Analyze sentence structure for introduction patterns"""
        
        introduction_starters = ['my', 'i', 'this', 'hello', 'hi', 'hey']
        
        words = text_lower.split()
        if not words:
            return False
        
        first_word = words[0]
        
        if first_word in introduction_starters:
            intro_patterns = [
                'my name is', 'i am', "i'm", 'this is',
                'hello i\'m', 'hi i\'m', 'hey i\'m'
            ]
            
            for pattern in intro_patterns:
                if text_lower.startswith(pattern):
                    return True
        
        return False
    
    def extract_name_mega_intelligent(self, text: str) -> Optional[str]:
        """ü§ñ SMART extraction using KoboldCPP with dynamic user validation"""
        
        print(f"[UltraIntelligentNameManager] ü§ñ KOBOLD EXTRACTION: '{text}'")
        
        if not text or len(text.strip()) < 3:
            return None
        
        # ü§ñ STEP 1: Use KoboldCPP + Hermes-2-Pro (your smart extraction)
        result = self.enhanced_extractor.extract_name_enhanced_aware(text)
        
        if not result:
            print(f"[UltraIntelligentNameManager] ü§ñ KoboldCPP found no name")
            return None
        
        print(f"[UltraIntelligentNameManager] ü§ñ KoboldCPP extracted: {result}")
        
        # üîß STEP 2: Smart validation (prioritizes ANY existing users)
        if self._smart_validate_extracted_name(result, text.lower()):
            print(f"[UltraIntelligentNameManager] ‚úÖ SMART VALIDATION PASSED: {result}")
            return result
        else:
            print(f"[UltraIntelligentNameManager] üõ°Ô∏è SMART VALIDATION FAILED: {result}")
            return None

    def _smart_validate_extracted_name(self, name: str, text_lower: str) -> bool:
        """üß† SMART validation that prioritizes ANY existing users"""
        
        if not name or len(name) < 2 or len(name) > 20:
            return False
        
        if not name.isalpha():
            return False
        
        name_lower = name.lower()
        
        # ‚úÖ PRIORITY 1: Always allow ANY existing users from your database
        existing_users = self._get_all_existing_users()
        
        if name_lower in existing_users:
            print(f"[UltraIntelligentNameManager] ‚úÖ EXISTING USER: {name}")
            return True
        
        # ‚úÖ PRIORITY 2: Check if it's a proper introduction context
        proper_intro_patterns = [
            r'my name is\s+' + re.escape(name_lower),
            r'call me\s+' + re.escape(name_lower),
            r'i\'?m\s+' + re.escape(name_lower) + r'(?:\s*,|\s*$|\s+by\s+the\s+way)',
            r'hello.*i\'?m\s+' + re.escape(name_lower),
            r'hi.*i\'?m\s+' + re.escape(name_lower),
            r'this is\s+' + re.escape(name_lower),
        ]
        
        has_proper_intro = any(re.search(pattern, text_lower) for pattern in proper_intro_patterns)
        
        if has_proper_intro:
            # ‚ùå BLOCK: Only obvious non-names in proper introduction context
            obvious_non_names = {
                'buddy', 'doing', 'going', 'working', 'checking', 'testing',
                'fine', 'good', 'okay', 'ready', 'busy', 'tired', 'here', 'there',
                'hello', 'thanks', 'sorry', 'yes', 'yeah', 'no', 'nope'
            }
            
            if name_lower in obvious_non_names:
                print(f"[UltraIntelligentNameManager] üõ°Ô∏è NON-NAME in intro context: {name}")
                return False
            
            # ‚ùå BLOCK: Possessive forms ("I'm David's friend")
            if f"{name_lower}'s" in text_lower:
                print(f"[UltraIntelligentNameManager] üõ°Ô∏è POSSESSIVE FORM: {name}")
                return False
            
            # ‚ùå BLOCK: Activity context ("I'm David working")
            activity_words = ['doing', 'going', 'working', 'here', 'there', 'fine', 'good', 'busy', 'tired']
            activity_pattern = rf"i\'?m\s+{re.escape(name_lower)}\s+({'|'.join(activity_words)})"
            
            if re.search(activity_pattern, text_lower):
                print(f"[UltraIntelligentNameManager] üõ°Ô∏è ACTIVITY CONTEXT: {name}")
                return False
            
            # ‚úÖ ALLOW: Proper introduction with reasonable name
            print(f"[UltraIntelligentNameManager] ‚úÖ PROPER INTRODUCTION: {name}")
            return True
        
        # ‚ùå REJECT: No proper introduction context found
        print(f"[UltraIntelligentNameManager] üõ°Ô∏è NO PROPER INTRO CONTEXT: {name}")
        return False

    def _get_all_existing_users(self) -> set:
        """üìö Get all existing users from all sources"""
        existing_users = set()
        
        try:
            # From known_users database
            if DATABASE_AVAILABLE:
                for username in known_users.keys():
                    if not username.startswith('Anonymous_') and not username.startswith('_'):
                        existing_users.add(username.lower())
                        
                        # Also add any nicknames/variants if stored
                        user_data = known_users[username]
                        if isinstance(user_data, dict):
                            # Check for stored name variants
                            variants = user_data.get('name_variants', [])
                            previous_names = user_data.get('previous_names', [])
                            
                            for variant in variants + previous_names:
                                if variant and isinstance(variant, str):
                                    existing_users.add(variant.lower())
            
            # From cultural name variants (for the current user context)
            if hasattr(self, 'cultural_name_variants'):
                for main_name, variants in self.cultural_name_variants.items():
                    existing_users.add(main_name.lower())
                    existing_users.update(variant.lower() for variant in variants)
            
            # From enhanced name database (common names)
            if hasattr(self, 'enhanced_name_database'):
                existing_users.update(self.enhanced_name_database)
            
            print(f"[UltraIntelligentNameManager] üìö Found {len(existing_users)} existing users/names")
            
        except Exception as e:
            print(f"[UltraIntelligentNameManager] ‚ùå Error getting existing users: {e}")
        
        return existing_users
        
    def _ultra_strict_name_validation(self, name: str, text_lower: str) -> bool:
        """üõ°Ô∏è ENHANCED Ultra-strict name validation with MEGA-COMPREHENSIVE blacklist"""
        
        if not name or len(name) < 2 or len(name) > 25:
            return False
        
        if not name.isalpha():
            return False
        
        name_lower = name.lower()
        
        # üîß NEW: Enhanced possessive/relationship blocking
        possessive_relationship_patterns = [
            rf"i'?m\s+{re.escape(name_lower)}'s\s+\w+",     # "I'm David's assistant"
            rf"i'?m\s+{re.escape(name_lower)}s\s+\w+",      # "I'm Davids friend" (no apostrophe)
            rf"i'?m\s+{re.escape(name_lower)}\s+from\s+\w+", # "I'm Dave from IT"
            rf"i'?m\s+\w+\s+{re.escape(name_lower)}'s\s+\w+", # "I'm with David's team"
        ]
        
        for pattern in possessive_relationship_patterns:
            if re.search(pattern, text_lower):
                print(f"[UltraIntelligentNameManager] üõ°Ô∏è POSSESSIVE RELATIONSHIP BLOCKED: {pattern}")
                return False
        
        # üõ°Ô∏è MEGA-COMPREHENSIVE BLACKLIST (ALL YOUR EXAMPLES + MORE)
        mega_blacklist = {
            # Common Whisper mistranscriptions (CRITICAL FOR BOBBY ISSUE)
            'bobby', 'robbie', 'tommy', 'jimmy', 'johnny', 'billy', 'willy', 'kenny',
            'danny', 'ricky', 'mickey', 'joey', 'tony', 'ronnie', 'donnie', 'stevie',
            
            # Emotional states
            'happy', 'sad', 'mad', 'glad', 'bad', 'good', 'great', 'fine', 'okay',
            'well', 'sick', 'hurt', 'sore', 'weak', 'strong', 'ready', 'busy',
            'tired', 'bored', 'scared', 'worried', 'excited', 'confused', 'lost',
            'found', 'free', 'available', 'late', 'early', 'sleepy', 'awake',
            
            # Actions and activities
            'doing', 'going', 'coming', 'working', 'talking', 'walking', 'running',
            'eating', 'drinking', 'sleeping', 'thinking', 'trying', 'playing',
            'singing', 'dancing', 'cooking', 'cleaning', 'shopping', 'driving',
            'flying', 'swimming', 'learning', 'teaching', 'helping', 'studying',
            'reading', 'writing', 'listening', 'watching', 'looking', 'seeing',
            'hearing', 'feeling', 'touching', 'smelling', 'tasting', 'moving',
            'sitting', 'standing', 'lying', 'resting', 'relaxing', 'chilling',
            'hanging', 'waiting', 'staying', 'leaving', 'arriving', 'departing',
            'traveling', 'visiting', 'exploring', 'discovering', 'finding',
            'searching', 'hunting', 'fishing', 'camping', 'hiking', 'climbing',
            
            # Locations and places
            'home', 'work', 'school', 'here', 'there', 'outside', 'inside',
            'upstairs', 'downstairs', 'online', 'offline', 'away', 'back',
            'near', 'far', 'close', 'distant', 'local', 'remote', 'downtown',
            'uptown', 'nearby', 'around', 'somewhere', 'nowhere', 'everywhere',
            'kitchen', 'bedroom', 'bathroom', 'living', 'dining', 'garage',
            'basement', 'attic', 'garden', 'yard', 'park', 'beach', 'mountain',
            'forest', 'desert', 'city', 'town', 'village', 'country', 'state',
            
            # Objects and things (YOUR EXAMPLES!)
            'kettle', 'bottle', 'table', 'chair', 'sofa', 'bed', 'desk', 'lamp',
            'phone', 'computer', 'laptop', 'tablet', 'camera', 'radio', 'tv',
            'car', 'bike', 'bus', 'train', 'plane', 'boat', 'ship', 'truck',
            'book', 'magazine', 'newspaper', 'journal', 'diary', 'notebook',
            'pen', 'pencil', 'paper', 'envelope', 'stamp', 'letter', 'package',
            'box', 'bag', 'purse', 'wallet', 'keys', 'glasses', 'watch',
            'ring', 'necklace', 'bracelet', 'earrings', 'hat', 'cap', 'helmet',
            'shirt', 'pants', 'dress', 'skirt', 'jacket', 'coat', 'shoes',
            'socks', 'underwear', 'pajamas', 'towel', 'blanket', 'pillow',
            
            # Relationships and family (YOUR EXAMPLES!)
            'friend', 'buddy', 'pal', 'mate', 'companion', 'partner', 'lover',
            'boyfriend', 'girlfriend', 'husband', 'wife', 'spouse', 'fiance',
            'mother', 'father', 'mom', 'dad', 'parent', 'child', 'son', 'daughter',
            'brother', 'sister', 'sibling', 'cousin', 'uncle', 'aunt', 'nephew',
            'niece', 'grandpa', 'grandma', 'grandfather', 'grandmother', 'grandchild',
            'grandson', 'granddaughter', 'ancestor', 'descendant', 'relative',
            'family', 'household', 'neighbor', 'roommate', 'classmate', 'teammate',
            'colleague', 'coworker', 'boss', 'employee', 'student', 'teacher',
            'doctor', 'nurse', 'lawyer', 'engineer', 'artist', 'musician',
            'bestie', 'bff', 'crush', 'enemy', 'rival', 'stranger', 'acquaintance',
            
            # Food and drinks
            'food', 'drink', 'water', 'coffee', 'tea', 'juice', 'beer', 'wine',
            'bread', 'butter', 'cheese', 'milk', 'eggs', 'meat', 'fish',
            'chicken', 'beef', 'pork', 'pizza', 'pasta', 'rice', 'soup',
            'apple', 'banana', 'orange', 'grape', 'strawberry', 'cookie',
            
            # Colors
            'red', 'blue', 'green', 'yellow', 'orange', 'purple', 'pink', 'brown',
            'black', 'white', 'gray', 'grey', 'silver', 'gold', 'bronze', 'copper',
            
            # Numbers
            'zero', 'one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight',
            'nine', 'ten', 'twenty', 'thirty', 'forty', 'fifty', 'hundred',
            
            # Time words
            'morning', 'afternoon', 'evening', 'night', 'today', 'tomorrow', 'yesterday',
            'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday',
            
            # Weather
            'sunny', 'cloudy', 'rainy', 'snowy', 'windy', 'stormy', 'foggy', 'hot', 'cold',
            
            # Common non-names and conversational words
            'voice', 'hello', 'goodbye', 'yes', 'yeah', 'yep', 'no', 'nope',
            'maybe', 'perhaps', 'possibly', 'probably', 'definitely', 'certainly',
            'thanks', 'thank', 'sorry', 'excuse', 'pardon', 'welcome', 'please',
            'help', 'stop', 'start', 'begin', 'end', 'finish', 'complete', 'continue',
            'pause', 'resume', 'repeat', 'again', 'once', 'twice'
        }
        
        # ‚úÖ LEGITIMATE INTRODUCTION PATTERNS
        legitimate_patterns = [
            r'my name is\s+\w+',
            r'my full name is\s+\w+',
            r'call me\s+\w+',
            r'you can call me\s+\w+',
            r'people call me\s+\w+',
            r'they call me\s+\w+',
            r'everyone calls me\s+\w+',
            r'my friends call me\s+\w+',
            r'i am called\s+\w+',
            r'i go by\s+\w+',
            r'everyone calls me\s+\w+',
            r'pleased to meet you.*my name is\s+\w+',
            r'nice to meet you.*i\'?m\s+\w+',
            r'hello.*my name is\s+\w+',
            r'hi.*my name is\s+\w+',
            r'hey.*my name is\s+\w+',
            r'good morning.*my name is\s+\w+',
            r'good afternoon.*my name is\s+\w+',
            r'good evening.*my name is\s+\w+',
            r'it\'?s me\s+\w+',
        ]
        
        # üß† CHECK: Is this a legitimate introduction pattern?
        has_legitimate_pattern = any(
            re.search(pattern, text_lower) for pattern in legitimate_patterns
        )
        
        # üõ°Ô∏è APPLY MEGA-BLACKLIST LOGIC
        if name_lower in mega_blacklist:
            if has_legitimate_pattern:
                # ‚úÖ LEGITIMATE: "My name is Bobby" - ALLOW
                print(f"[UltraIntelligentNameManager] ‚úÖ LEGITIMATE NAME OVERRIDE: {name} (explicit introduction)")
                
                # üîç EXTRA VALIDATION: Check if name is in our known names database
                if name_lower in self.enhanced_name_database:
                    print(f"[UltraIntelligentNameManager] ‚úÖ CONFIRMED: {name} is in name database")
                    return True
                else:
                    print(f"[UltraIntelligentNameManager] ‚ö†Ô∏è WARNING: {name} not in database but legitimate pattern detected")
                    return True
            else:
                # ‚ùå WHISPER ERROR or CASUAL: "I'm bobby", "I'm kettle", "Her name is bestie" - BLOCK
                print(f"[UltraIntelligentNameManager] üõ°Ô∏è MEGA-BLACKLIST BLOCKED: {name} (pattern: {text_lower})")
                return False
        
        # ‚úÖ CONTEXTUAL VALIDATION for casual conversation patterns
        casual_context_patterns = [
            rf"i'?m {name_lower} (fine|good|great|okay|well|better|ready|busy|free|here|there|back|done|sorry|tired)",
            rf"i'?m {name_lower} (to|for|with|at|in|on|out|up|down)",
            rf"i'?m {name_lower} (and|but|or|so|then|now|today|tomorrow)",
            rf"her name is {name_lower}",
            rf"his name is {name_lower}",
            rf"she'?s {name_lower}",
            rf"he'?s {name_lower}",
            rf"they'?re {name_lower}",
            rf"we'?re {name_lower}",
            rf"it'?s {name_lower}",
            rf"that'?s {name_lower}",
            rf"this is {name_lower}(?!$)"  # "this is bobby talking" but not "this is bobby"
        ]
        
        for pattern in casual_context_patterns:
            if re.search(pattern, text_lower):
                print(f"[UltraIntelligentNameManager] üõ°Ô∏è CASUAL CONTEXT REJECTION: {pattern}")
                return False
        
        print(f"[UltraIntelligentNameManager] üõ°Ô∏è ULTRA-STRICT VALIDATION PASSED: {name}")
        return True
    
    def handle_ultra_intelligent_spontaneous_introduction(self, name: str, text: str) -> Tuple[str, str]:
        """üé≠ Handle introduction and establish actual person name"""
        
        try:
            # Apply same name collision handling
            final_name = handle_same_name_collision(name)
            
            # üîß FIX: Establish actual person name (not computer login)
            if not self.actual_person_name:
                self.actual_person_name = final_name
                self.person_nicknames = self._build_current_user_nicknames()
                print(f"[UltraIntelligentNameManager] üë§ PERSON NAME ESTABLISHED: {final_name}")
            
            # Update voice clustering
            self._update_voice_clustering_after_name_recognition(final_name)
            
            # Record introduction
            self.spontaneous_introductions.append({
                'name': final_name,
                'original_text': text,
                'timestamp': datetime.utcnow().isoformat(),
                'confidence': 0.95,
                'validation_method': 'ultra_intelligent',
                'voice_cluster_linked': True
            })
            
            return final_name, "ULTRA_INTELLIGENT_INTRODUCTION"
            
        except Exception as e:
            print(f"[UltraIntelligentNameManager] ‚ùå Introduction error: {e}")
            return name, "ULTRA_INTELLIGENT_ERROR"
    
    def _link_relevant_clusters_to_name(self, name: str):
        """üîó Link relevant anonymous clusters to name"""
        try:
            if not anonymous_clusters:
                return
            
            # Find the most recently active cluster
            most_recent_cluster = None
            most_recent_time = None
            
            for cluster_id, cluster_data in anonymous_clusters.items():
                last_updated = datetime.fromisoformat(cluster_data.get('last_updated', '2025-01-01T00:00:00'))
                
                if most_recent_time is None or last_updated > most_recent_time:
                    most_recent_time = last_updated
                    most_recent_cluster = cluster_id
            
            # Link the most recent cluster to the name
            if most_recent_cluster:
                success = link_anonymous_to_named(most_recent_cluster, name)
                if success:
                    print(f"[UltraIntelligentNameManager] üîó Linked {most_recent_cluster} to {name}")
                    self.cluster_name_associations[most_recent_cluster] = name
                    
        except Exception as e:
            print(f"[UltraIntelligentNameManager] ‚ùå Cluster linking error: {e}")
    
    def _analyze_conversation_context(self, text: str) -> Dict:
        """üß† Analyze conversation context for ultra-intelligence"""
        return self.conversation_context_analyzer.analyze_context(text)
    
    def _get_suspicious_reasons(self, name: str, text: str) -> List[str]:
        """üìä Get detailed reasons why name is suspicious"""
        reasons = []
        name_lower = name.lower()
        text_lower = text.lower()
        
        if self.is_fake_name_trap(name):
            reasons.append("fake_name_trap")
        if self.is_possessive_or_relation_trap(name, text):
            reasons.append("possessive_relation_trap")
        if "buddy" in text_lower and name_lower.startswith("b"):
            reasons.append("buddy_confusion")
        if name_lower not in self.enhanced_name_database:
            reasons.append("unknown_name")
        if len(name_lower) < 3:
            reasons.append("short_name")
        if not re.search(r"\bmy\s+name\s+is\b|\bcall\s+me\b", text_lower):
            reasons.append("no_explicit_intro")
        
        return reasons

    # ========== NAME CHANGE METHODS ==========
    
    def is_name_change_command(self, text: str) -> bool:
        """üîÑ Check if user wants to change their name"""
        change_patterns = [
            "change my name", "rename me", "call me something else",
            "change name", "new name", "different name",
            "can you change my name", "buddy change my name",
            "i want to change my name", "change what you call me"
        ]
        text_lower = text.lower()
        return any(pattern in text_lower for pattern in change_patterns)
    
    def handle_name_change_request(self, text: str) -> Tuple[str, str]:
        """üîÑ Handle request to change name"""
        print("[UltraIntelligentNameManager] üîÑ Name change requested")
        
        new_name = self.extract_new_name_from_change_request(text)
        if new_name:
            print(f"[UltraIntelligentNameManager] üë§ New name in request: {new_name}")
            return self.confirm_name_change(new_name)
        else:
            speak_streaming("Sure! What would you like me to call you?")
            self.waiting_for_new_name = True
            return "CurrentUser", "WAITING_FOR_NEW_NAME"
    
    def extract_new_name_from_change_request(self, text: str) -> Optional[str]:
        """üìù Extract new name from change request"""
        patterns = [
            r"change my name to (\w+)",
            r"call me (\w+)",
            r"rename me (\w+)",
            r"change name to (\w+)",
            r"new name is (\w+)",
            r"my name is (\w+)"
        ]
        
        for pattern in patterns:
            match = re.search(pattern, text.lower())
            if match:
                name = match.group(1).title()
                if self._ultra_strict_name_validation(name, text.lower()):
                    return name
        return None

    def handle_new_name_response(self, text: str) -> Tuple[str, str]:
        """üìù Handle response when asking for new name"""
        new_name = self.extract_flexible_name_from_text(text)
        if new_name:
            print(f"[UltraIntelligentNameManager] üë§ New name received: {new_name}")
            return self.confirm_name_change(new_name)
        else:
            speak_streaming("I didn't catch that name clearly. Just say the name you want.")
            return "CurrentUser", "WAITING_FOR_NEW_NAME"
    
    def extract_flexible_name_from_text(self, text: str) -> Optional[str]:
        """üîç Flexible name extraction for name changes"""
        patterns = [
            r"^(\w+)$",
            r"call me (\w+)",
            r"my name is (\w+)",
            r"i'm (\w+)",
            r"i am (\w+)",
            r"it's (\w+)",
            r"just (\w+)"
        ]
        
        text_lower = text.lower().strip()
        
        for pattern in patterns:
            match = re.search(pattern, text_lower)
            if match:
                name = match.group(1).title()
                if self._ultra_strict_name_validation(name, text_lower):
                    return name
        return None
    
    def confirm_name_change(self, new_name: str) -> Tuple[str, str]:
        """‚úÖ Confirm name change"""
        self.new_name_suggestion = new_name
        self.waiting_for_new_name = False
        self.pending_name_change_confirmation = True
        
        speak_streaming(f"I will call you {new_name}. Is that correct?")
        return "CurrentUser", "CONFIRMING_NAME_CHANGE"
    
    def handle_name_change_confirmation(self, text: str) -> Tuple[str, str]:
        """‚úÖ Handle name change confirmation"""
        text_lower = text.lower().strip()
        
        if any(word in text_lower for word in ["yes", "yeah", "correct", "right", "ok"]):
            return self.execute_name_change()
        elif any(word in text_lower for word in ["no", "nope", "wrong"]):
            speak_streaming("What would you like me to call you?")
            self.pending_name_change_confirmation = False
            self.waiting_for_new_name = True
            return "CurrentUser", "WAITING_FOR_NEW_NAME"
        else:
            speak_streaming(f"I will call you {self.new_name_suggestion}. Is that correct?")
            return "CurrentUser", "CONFIRMING_NAME_CHANGE"
    
    def execute_name_change(self) -> Tuple[str, str]:
        """üîÑ Execute the name change"""
        try:
            # Find and update profile
            for username, profile_data in known_users.items():
                if isinstance(profile_data, dict) and profile_data.get('status') in ['learning', 'trained']:
                    profile_data['username'] = self.new_name_suggestion
                    profile_data['last_updated'] = datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')
                    profile_data.setdefault('previous_names', []).append(username)
                    
                    known_users[self.new_name_suggestion] = profile_data
                    if username != self.new_name_suggestion:
                        del known_users[username]
                    
                    save_known_users()
                    break
            
            speak_streaming(f"Great! I'll call you {self.new_name_suggestion} from now on.")
            self.reset_name_change_state()
            return self.new_name_suggestion, "NAME_CHANGED"
            
        except Exception as e:
            print(f"[UltraIntelligentNameManager] ‚ùå Name change error: {e}")
            speak_streaming(f"I'll call you {self.new_name_suggestion} from now on.")
            self.reset_name_change_state()
            return self.new_name_suggestion, "NAME_NOTED"
    
    def reset_name_change_state(self):
        """üîÑ Reset name change state"""
        self.waiting_for_new_name = False
        self.pending_name_change_confirmation = False
        self.old_name = None
        self.new_name_suggestion = None

    # ========== ADDITIONAL UTILITY METHODS ==========
    
    def get_introduction_statistics(self) -> Dict:
        """üìä Get statistics about introductions processed"""
        total_introductions = len(self.spontaneous_introductions)
        total_false_positives = len(self.false_positive_learning)
        
        if total_introductions == 0:
            accuracy = 1.0
        else:
            accuracy = (total_introductions - total_false_positives) / total_introductions
        
        return {
            'total_introductions': total_introductions,
            'total_false_positives': total_false_positives,
            'accuracy_rate': accuracy,
            'confidence_history': dict(self.name_confidence_history),
            'learning_entries': total_false_positives,
            'blacklist_blocks': getattr(self, '_blacklist_block_count', 0),
            'whisper_error_blocks': getattr(self, '_whisper_error_block_count', 0)
        }

    def debug_name_processing(self, text: str) -> str:
        """üêõ Debug name processing for troubleshooting"""
        debug_info = {
            'input_text': text,
            'phase_1_command_detection': self._is_ultra_intelligent_command_detection(text.lower()),
            'phase_1_whisper_error': self._is_whisper_error_pattern(text.lower()),
            'phase_1_casual_conversation': self._is_casual_conversation_pattern(text.lower()),
            'phase_2_conversation_context': self.conversation_context_analyzer.analyze_context(text),
            'phase_3_linguistic_analysis': self.linguistic_validator.analyze_introduction_patterns(text.lower()),
            'phase_4_introduction_score': self._calculate_ultra_intelligent_introduction_score(text.lower()),
            'extracted_name': self._extract_potential_name_from_text(text.lower()),
            'final_decision': self.is_ultra_intelligent_spontaneous_introduction(text),
            'validation_timestamp': datetime.utcnow().isoformat()
        }
        
        debug_output = []
        debug_output.append(f"üß† ULTRA-INTELLIGENT NAME PROCESSING DEBUG")
        debug_output.append(f"Input: '{text}'")
        debug_output.append(f"")
        debug_output.append(f"Phase 1 Rejections:")
        debug_output.append(f"  Command Detection: {debug_info['phase_1_command_detection']}")
        debug_output.append(f"  Whisper Error: {debug_info['phase_1_whisper_error']}")
        debug_output.append(f"  Casual Conversation: {debug_info['phase_1_casual_conversation']}")
        debug_output.append(f"")
        debug_output.append(f"Phase 2 Context Analysis:")
        debug_output.append(f"  Type: {debug_info['phase_2_conversation_context']['conversation_type']}")
        debug_output.append(f"  Formality: {debug_info['phase_2_conversation_context']['formality_level']}")
        debug_output.append(f"  Tone: {debug_info['phase_2_conversation_context']['emotional_tone']}")
        debug_output.append(f"")
        debug_output.append(f"Phase 3 Linguistic Analysis:")
        debug_output.append(f"  Confidence: {debug_info['phase_3_linguistic_analysis']['confidence']:.3f}")
        debug_output.append(f"  Factors: {debug_info['phase_3_linguistic_analysis']['factors']}")
        debug_output.append(f"")
        debug_output.append(f"Phase 4 Introduction Score: {debug_info['phase_4_introduction_score']:.3f}")
        debug_output.append(f"Extracted Name: {debug_info['extracted_name']}")
        debug_output.append(f"Final Decision: {debug_info['final_decision']}")
        
        return "\n".join(debug_output)

# ========== TESTING SECTION ==========

def test_enhanced_system():
    """üß™ Test the enhanced name extraction system"""
    
    print("üöÄ INITIALIZING ULTRA-INTELLIGENT NAME MANAGER")
    print("=" * 60)
    
    try:
        manager = UltraIntelligentNameManager()
        print("‚úÖ Manager initialized successfully")
    except Exception as e:
        print(f"‚ùå Manager initialization failed: {e}")
        return
    
    # Test cases
    test_cases = [
        # ‚úÖ Positive, should extract
        ("im david", "David"),
        ("been pretty busy today im david by the way", "David"),
        ("thanks my name is david", "David"),
        ("thanks im david", "David"),
        ("im david, annas friend", "David"),
        ("hey im david nice to meet you", "David"),
        ("im David", "David"),
        ("IM DAVID", "David"),
        ("Im David", "David"),
        ("my name is David", "David"),
        ("it's me David", "David"),
        ("Hello, my name is David.", "David"),
        ("Hi, I'm David!", "David"),
        ("Yo, im David.", "David"),
        ("They call me David", "David"),

        # ‚úÖ Edge: mixed with filler
        ("uh im david you know", "David"),
        ("hmm i think i said im david", "David"),
        ("by the way im david", "David"),
        ("like i said im david", "David"),

        # ‚úÖ Extra spaces and punctuation
        ("   im    david   ", "David"),
        ("im david.", "David"),
        ("im david!", "David"),
        ("im david?", "David"),
        ("im david,", "David"),

        # ‚úÖ Nickname style
        ("call me Dave", "Dave"),
        ("my friends call me Davey", "Davey"),
        ("yo, people call me Dave", "Dave"),

        # üö® Negative: should block
        ("im david's assistant", None),
        ("im daveys dad", None),
        ("im here with david", None),
        ("im working with david", None),
        ("im dave from IT", None),
        ("im at work", None),
        ("im so tired", None),
        ("im going home", None),
        ("im your friend", None),
        ("im his helper", None),
        ("im doing fine", None),
        ("im on my way", None),
        ("im almost done", None),

        # üö® Edge negative
        ("my boss is david", None),
        ("i work for david", None),
        ("met david today", None),
        ("im on david's team", None),
        ("we spoke with david", None),
    ]           
    print("\nüß™ TESTING ENHANCED NAME EXTRACTION")
    print("=" * 60)
    
    for i, (text, expected) in enumerate(test_cases, 1):
        print(f"\nüìù TEST {i}: '{text}'")
        print("-" * 40)
        
        try:
            # Test the introduction detection
            is_intro = manager.is_ultra_intelligent_spontaneous_introduction(text)
            print(f"üîç Introduction detected: {is_intro}")
            
            if is_intro:
                # Test name extraction
                extracted_name = manager.extract_name_mega_intelligent(text)
                print(f"üéØ Extracted name: {extracted_name}")
                
                # Check result
                if extracted_name == expected:
                    print(f"‚úÖ PASS - Expected: {expected}, Got: {extracted_name}")
                else:
                    print(f"‚ùå FAIL - Expected: {expected}, Got: {extracted_name}")
            else:
                if expected is None:
                    print(f"‚úÖ PASS - Correctly blocked introduction")
                else:
                    print(f"‚ùå FAIL - Should have extracted: {expected}")
                    
        except Exception as e:
            print(f"‚ùå ERROR during test: {e}")
    
    print("\nüéâ TESTING COMPLETE")
    print("=" * 60)

def test_kobold_connection():
    """üîç Test KoboldCPP connection"""
    
    print("\nü§ñ TESTING KOBOLDCPP CONNECTION")
    print("=" * 40)
    
    try:
        extractor = KoboldCppNameExtractor()
        connected = extractor.test_connection()
        
        if connected:
            print("‚úÖ KoboldCPP connection successful")
            
            # Test simple extraction
            test_text = "My name is David"
            result = extractor.extract_name(test_text)
            print(f"üéØ Test extraction result: {result}")
            
        else:
            print("‚ùå KoboldCPP connection failed")
            print("üí° Make sure KoboldCPP is running on http://localhost:5001")
            
    except Exception as e:
        print(f"‚ùå KoboldCPP test error: {e}")

if __name__ == "__main__":
    print("üß† ULTRA-INTELLIGENT NAME MANAGER - STANDALONE TEST")
    print("=" * 60)
    
    # Test KoboldCPP connection first
    test_kobold_connection()
    
    # Test the enhanced system
    test_enhanced_system()

# Global ultra-intelligent name manager
NameManager = UltraIntelligentNameManager